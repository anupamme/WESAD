{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/santteegt/om-fol-timeseries/blob/master/WESAD_Data_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPBxt5U64v8n"
   },
   "source": [
    "# WESAD - A Multimodal Dataset for Wearable Stress and Affect Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scMGFUBL1cVY"
   },
   "source": [
    "## Requires Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "vPwtauZv0M-M",
    "outputId": "7d9022f3-77c8-4200-e391-0f2863057120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neurokit2 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (0.0.36)\n",
      "Requirement already satisfied: pyhrv in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: matplotlib in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from neurokit2) (3.2.1)\n",
      "Requirement already satisfied: pandas in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from neurokit2) (1.0.3)\n",
      "Requirement already satisfied: numpy in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from neurokit2) (1.18.4)\n",
      "Requirement already satisfied: scipy in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from neurokit2) (1.4.1)\n",
      "Requirement already satisfied: sklearn in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from neurokit2) (0.0)\n",
      "Requirement already satisfied: nolds in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from pyhrv) (0.5.2)\n",
      "Requirement already satisfied: biosppy in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from pyhrv) (0.6.1)\n",
      "Requirement already satisfied: spectrum in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from pyhrv) (0.7.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from matplotlib->neurokit2) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from matplotlib->neurokit2) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from matplotlib->neurokit2) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from matplotlib->neurokit2) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from pandas->neurokit2) (2020.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from sklearn->neurokit2) (0.23.0)\n",
      "Requirement already satisfied: setuptools in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from nolds->pyhrv) (46.1.3.post20200330)\n",
      "Requirement already satisfied: future in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from nolds->pyhrv) (0.18.2)\n",
      "Requirement already satisfied: six in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from biosppy->pyhrv) (1.14.0)\n",
      "Requirement already satisfied: bidict in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from biosppy->pyhrv) (0.19.0)\n",
      "Requirement already satisfied: shortuuid in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from biosppy->pyhrv) (1.0.1)\n",
      "Requirement already satisfied: h5py in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from biosppy->pyhrv) (2.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from scikit-learn->sklearn->neurokit2) (2.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from scikit-learn->sklearn->neurokit2) (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install neurokit2 pyhrv pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REMGlK_Z3zq6"
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from datetime import timedelta\n",
    "\n",
    "import gzip\n",
    "import logging\n",
    "import matplotlib as plt\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyhrv\n",
    "import scipy.signal as scisig\n",
    "import scipy.stats\n",
    "import shutil\n",
    "import time\n",
    "from urllib.request import Request, urlopen\n",
    "import zipfile\n",
    "\n",
    "import cvxEDA\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 7]  # Bigger images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "zuYTKZ-I1Mcb",
    "outputId": "2b2e7e05-3a94-44f7-ed14-3c1014aed66d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('cvxEDA.py'):\n",
    "    !wget https://raw.githubusercontent.com/lciti/cvxEDA/master/src/cvxEDA.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "yLIJiqRh0H21",
    "outputId": "b4934fb3-6fe8-4426-a889-20e09b9b4f55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2224\r\n",
      "-rw-r--r--  1 santteegt  staff       20 Jun 11 10:10 README.md\r\n",
      "-rw-r--r--  1 santteegt  staff  1125495 Jun 11 10:33 WESAD_Data_Exploration.ipynb\r\n",
      "drwxr-xr-x  3 santteegt  staff       96 Jun 11 10:13 \u001b[34m__pycache__\u001b[m\u001b[m\r\n",
      "-rw-r--r--  1 santteegt  staff     5876 Jun 11 10:12 cvxEDA.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PSRQ7dUs33ru"
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FkU_oqlJh9Jm"
   },
   "outputs": [],
   "source": [
    "class WesadDataLoader():\n",
    "    \"\"\"Downloads and load data from the WESAD dataset\n",
    "        \n",
    "        Source URI: https://uni-siegen.sciebo.de/s/pYjSgfOVs6Ntahr/download\n",
    "    \"\"\"\n",
    "    \n",
    "    LABEL = 'label'\n",
    "    SIGNAL = 'signal'\n",
    "    SUBJECT = 'subject'\n",
    "    \n",
    "    WRIST_DEV = 'wrist'\n",
    "    CHEST_DEV = 'chest'\n",
    "    \n",
    "    DATASET_NAME = 'WESAD'\n",
    "    DATASET_URI = 'https://uni-siegen.sciebo.de/s/pYjSgfOVs6Ntahr/download'\n",
    "    \n",
    "    def __init__(self, subject, basepath='.'):\n",
    "        self.logger = logging.getLogger(WesadDataLoader.__name__)\n",
    "        self.logger.info('Init...')\n",
    "        self.chest_modalities = ['ACC', 'ECG', 'EDA', 'EMG', 'Resp', 'Temp']\n",
    "        self.wrist_modalities = ['ACC', 'BVP', 'EDA', 'TEMP']\n",
    "        self.mod_samp_rate = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4, 'chest': 700}  # Hz\n",
    "        WesadDataLoader.download(basepath)\n",
    "        basepath = os.path.join(os.path.abspath(basepath), WesadDataLoader.DATASET_NAME, subject)\n",
    "        if not os.path.isdir(basepath):\n",
    "            raise Exception(f'Dataset path does not exist or is not a directory: {basepath}')\n",
    "        data_file = os.path.join(basepath, f'{subject}.pkl')\n",
    "        if not os.path.exists(data_file):\n",
    "            raise Exception(f'Data file does not exists: {data_file}')\n",
    "#         with open(subject + '.pkl', 'rb') as file:\n",
    "#             data = pickle.load(file, encoding='latin1')\n",
    "        self.data = pd.read_pickle(data_file)\n",
    "    \n",
    "    @staticmethod\n",
    "    def download(basepath):\n",
    "        filename = os.path.join(os.path.abspath(basepath), f'{WesadDataLoader.DATASET_NAME}.zip')\n",
    "        data_folder = os.path.join(os.path.abspath(basepath), WesadDataLoader.DATASET_NAME)\n",
    "        if not os.path.isdir(data_folder) and not os.path.exists(filename):\n",
    "            print('Downloading dataset...')\n",
    "            start = time.time()\n",
    "            response = urlopen(WesadDataLoader.DATASET_URI)\n",
    "            print(f'Elapsed: {time.time() - start} secs')\n",
    "        if not os.path.isdir(data_folder):\n",
    "            with open(filename, 'wb') as out_file:\n",
    "                print('Saving dataset locally...')\n",
    "                start = time.time()\n",
    "                shutil.copyfileobj(response, out_file)\n",
    "            out_file.close()\n",
    "            print(f'Elapsed: {time.time() - start} secs')\n",
    "            start = time.time()\n",
    "            while not zipfile.is_zipfile(filename):\n",
    "                print('Wait..')\n",
    "            print('Found Zip...')\n",
    "            print(f'Elapsed: {time.time() - start} secs')\n",
    "            with zipfile.ZipFile(filename) as zf:\n",
    "                print('Extracting files...')\n",
    "                start = time.time()\n",
    "                zf.extractall()\n",
    "            print(f'Elapsed: {time.time() - start} secs')\n",
    "            print('Done!')\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.data[WesadDataLoader.LABEL]\n",
    "\n",
    "    def get_wrist_data(self):\n",
    "        \"\"\"\"\"\"\n",
    "        #label = self.data[self.keys[0]]\n",
    "#         assert subject == self.data[self.keys[1]]\n",
    "        signal = self.data[WesadDataLoader.SIGNAL]\n",
    "        wrist_data = signal[WesadDataLoader.WRIST_DEV]\n",
    "        # Adding Resp modality from chest device\n",
    "        wrist_data.update({'Resp': self.data[WesadDataLoader.SIGNAL][WesadDataLoader.CHEST_DEV]['Resp']})\n",
    "        return wrist_data\n",
    "\n",
    "    def get_chest_data(self):\n",
    "        \"\"\"\"\"\"\n",
    "        signal = self.data[WesadDataLoader.SIGNAL]\n",
    "        chest_data = signal[WesadDataLoader.CHEST_DEV]\n",
    "        return chest_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXQ_4tv137W2"
   },
   "source": [
    "## Data Exploration - Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "qS5OCLaidPcu",
    "outputId": "5ff81558-0b7f-4158-8d18-0f1e6bc43cd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.8 s, sys: 27.2 s, total: 1min 20s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BASE_PATH = './'\n",
    "# WesadDataLoader.download('.')\n",
    "DATASET_PATH = os.path.join(BASE_PATH, WesadDataLoader.DATASET_NAME)\n",
    "subjects = [dir_ for dir_ in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, dir_))]\n",
    "# subjects = ['S3']\n",
    "obj_data = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    obj_data[subject] = WesadDataLoader(subject=subject, basepath=BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "1ASOr67U9Eke",
    "outputId": "cea3f8e1-99ac-4247-f798-673658deb793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects dict_keys(['S5', 'S2', 'S3', 'S4', 'S17', 'S10', 'S11', 'S16', 'S8', 'S6', 'S7', 'S9', 'S13', 'S14', 'S15'])\n",
      "Subject S5 8148\n",
      "Subject S2 7764\n",
      "Subject S3 7900\n",
      "Subject S4 7941\n",
      "Subject S17 8384\n",
      "Subject S10 8388\n",
      "Subject S11 8192\n",
      "Subject S16 8165\n",
      "Subject S8 8116\n",
      "Subject S6 8088\n",
      "Subject S7 8073\n",
      "Subject S9 8068\n",
      "Subject S13 8185\n",
      "Subject S14 8189\n",
      "Subject S15 8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23206404, 121813)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dataset size\n",
    "sampling_rate=700\n",
    "window_size=60\n",
    "window_shift=0.25\n",
    "\n",
    "baseline_rec = 0\n",
    "stress_rec = 0\n",
    "amusement_rec = 0\n",
    "total_segmented = 0\n",
    "print('Subjects', obj_data.keys())\n",
    "for sub in obj_data.keys():\n",
    "    data = obj_data[sub].get_chest_data()\n",
    "    labels = obj_data[sub].get_labels()\n",
    "    baseline = np.asarray([idx for idx,val in enumerate(labels) if val == 1])\n",
    "    stress = np.asarray([idx for idx,val in enumerate(labels) if val == 2])\n",
    "    amusement = np.asarray([idx for idx,val in enumerate(labels) if val == 3])\n",
    "\n",
    "    baseline_rec += baseline.shape[0]\n",
    "    stress_rec += stress.shape[0]\n",
    "    amusement_rec += amusement.shape[0]\n",
    "    conditions = [baseline, stress, amusement]\n",
    "    \n",
    "    subtotal = 0\n",
    "    for cond in conditions:\n",
    "        subtotal += len(list(range(0, data['ACC'][cond].shape[0] - (sampling_rate * window_size), int(sampling_rate * window_shift))))\n",
    "    print('Subject', sub, subtotal)\n",
    "    total_segmented += subtotal\n",
    "\n",
    "(baseline_rec + stress_rec + amusement_rec), total_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2wH1VOlIOTX"
   },
   "outputs": [],
   "source": [
    "def get_slope(series):\n",
    "    linreg = scipy.stats.linregress(np.arange(len(series)), series )\n",
    "    slope = linreg[0]\n",
    "    return slope\n",
    "\n",
    "\n",
    "def get_freq_features(series):\n",
    "    # Peak frequency is simply the frequency of maximum power\n",
    "    f, Pxx = scisig.periodogram(series) # Estimate power spectral density (PSD) using a periodogram\n",
    "    psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "    peak_freq = psd_dict[max(psd_dict.keys())]\n",
    "    # Mean freq: http://luscinia.sourceforge.net/page26/page35/page35.html\n",
    "    mean_freq = np.dot(Pxx, f) / np.sum(Pxx)\n",
    "    avg_power = np.sum(Pxx) / 2\n",
    "    # Median freq: http://luscinia.sourceforge.net/page26/page36/page36.html\n",
    "    median_freq = f[(np.cumsum(f) > avg_power).argmax()]\n",
    "\n",
    "    return peak_freq, mean_freq, median_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8m_8eOSjmoJ"
   },
   "source": [
    "### Methods for Computing Features on Chest-based modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVvvC6NAbn30"
   },
   "outputs": [],
   "source": [
    "def compute_features(data, condition, sampling_rate=700, window_size=60, window_shift=0.25):\n",
    "\n",
    "    index = 0\n",
    "    init = time.time()\n",
    "\n",
    "    # data cleaning\n",
    "    ## ECG\n",
    "    ecg_cleaned = nk.ecg_clean(data[\"ECG\"][condition].flatten(), sampling_rate=sampling_rate)\n",
    "    ## == OLD\n",
    "    # ecg_rpeaks, _ = nk.ecg_peaks(ecg_cleaned, sampling_rate=sampling_rate)\n",
    "    # ecg_hr = nk.signal_rate(ecg_rpeaks, sampling_rate=sampling_rate)\n",
    "    ## ==\n",
    "    ## EDA\n",
    "    ## 5Hz lowpass filter\n",
    "    eda_highcut = 5\n",
    "    eda_filtered = nk.signal_filter(data['EDA'][condition].flatten(), sampling_rate=sampling_rate, highcut=eda_highcut)\n",
    "    eda_cleaned = nk.standardize(eda_filtered)\n",
    "    # TODO: not sure about the approach. cvxeda takes longer periods\n",
    "    # phasic_tonic = nk.eda_phasic(cleaned, sampling_rate=700, method='cvxeda')\n",
    "    eda_phasic_tonic = nk.eda_phasic(eda_cleaned, sampling_rate=sampling_rate)\n",
    "    eda_phasic_tonic['t'] = [(1 / sampling_rate) * i for i in range(eda_phasic_tonic.shape[0])]\n",
    "    eda_scr_peaks, scr_info = nk.eda_peaks(eda_phasic_tonic['EDA_Phasic'], sampling_rate=sampling_rate)\n",
    "    ## EMG\n",
    "    ## For 5 sec window signal\n",
    "    ## More on DC Bias https://www.c-motion.com/v3dwiki/index.php/EMG:_Removing_DC_Bias\n",
    "    emg_lowcut = 50\n",
    "    emg_filtered_dc = nk.signal_filter(data['EMG'][condition].flatten(), sampling_rate=sampling_rate, lowcut=emg_lowcut)\n",
    "    # OR 100 Hz highpass Butterworth filter followed by a constant detrending\n",
    "    # filtered_dc = nk.emg_clean(chest_data_dict['EMG'][baseline].flatten(), sampling_rate=700)\n",
    "    ## For 60 sec window signal\n",
    "    # 50Hz lowpass filter\n",
    "    emg_highcut = 50\n",
    "    emg_filtered = nk.signal_filter(data['EMG'][condition].flatten(), sampling_rate=sampling_rate, highcut=emg_highcut)\n",
    "    ## Resp\n",
    "    ## Method biosppy important to appply bandpass filter 0.1 - 0.35 Hz\n",
    "    resp_processed, _ = nk.rsp_process(data['Resp'][condition].flatten(), sampling_rate=sampling_rate, method='biosppy')\n",
    "\n",
    "    print('Elapsed Preprocess', str(timedelta(seconds=time.time() - init)))\n",
    "    init = time.time()\n",
    "\n",
    "    chest_df_5 = pd.DataFrame() # For 5 sec window size\n",
    "    chest_df = pd.DataFrame()\n",
    "\n",
    "    window = int(sampling_rate * window_size)\n",
    "    for i in range(0, data['ACC'][condition].shape[0] - window, int(sampling_rate * window_shift)):\n",
    "\n",
    "        # ACC\n",
    "        w_acc_data = data['ACC'][condition][i: window + i]\n",
    "        acc_x_mean, acc_y_mean, acc_z_mean = np.mean(w_acc_data, axis=0)  # Feature\n",
    "        acc_x_std, acc_y_std, acc_z_std = np.std(w_acc_data, axis=0)  # Feature\n",
    "        acc_x_peak, acc_y_peak, acc_z_peak = np.amax(w_acc_data, axis=0)  # Feature\n",
    "        acc_x_absint, acc_y_absint, acc_z_absint = np.abs(np.trapz(w_acc_data, axis=0))  # Feature\n",
    "        xyz = np.sum(w_acc_data, axis=0)\n",
    "        xyz_mean = np.mean(xyz)  # Feature\n",
    "        xyz_std = np.std(xyz)  # Feature\n",
    "        xyz_absint = np.abs(np.trapz(xyz))  # Feature\n",
    "\n",
    "\n",
    "        # == OLD\n",
    "        # ## ECG\n",
    "        # w_ecg_rpeaks = ecg_rpeaks[i: window + i]\n",
    "        # # HR\n",
    "        # w_ecg_hr = ecg_hr[i: window + i]\n",
    "        # hr_mean = np.mean(w_ecg_hr)  # Feature\n",
    "        # hr_std = np.std(w_ecg_hr)  # Feature\n",
    "        # # HRV Time-domain Indices\n",
    "        # # HRV_MeanNN\n",
    "        # # HRV_SDNN\n",
    "        # # HRV_pNN50\n",
    "        # # HRV_RMSSD -> Root mean square of the HRV\n",
    "        # # HRV_HTI -> Triangular interpolation index\n",
    "        # hrv_time = nk.hrv_time(w_ecg_rpeaks, sampling_rate=sampling_rate, show=False)\n",
    "        # hrv_mean = hrv_time.loc[0, 'HRV_MeanNN']  # Feature\n",
    "        # hrv_std = hrv_time.loc[0, 'HRV_SDNN']  # Feature\n",
    "        # # TODO: NN50\n",
    "        # # hrv_NN50 = \n",
    "        # hrv_pNN50 = hrv_time.loc[0, 'HRV_pNN50']  # Feature\n",
    "        # hrv_TINN = hrv_time.loc[0, 'HRV_HTI']  # Feature\n",
    "        # hrv_rms = hrv_time.loc[0, 'HRV_RMSSD']  # Feature\n",
    "\n",
    "        # # HRV Frequency-domain Indices\n",
    "        # # TODO: get NaN values within windows (*)\n",
    "        # # HRV_ULF *\n",
    "        # # HRV_LF *\n",
    "        # # HRV_HF \n",
    "        # # HRV_VHF\n",
    "        # # HRV_LFHF - Ratio LF/HF *\n",
    "        # # HRV_LFn *\n",
    "        # # HRV_HFn\n",
    "        # hrv_freq = nk.hrv_frequency(w_ecg_rpeaks, sampling_rate=sampling_rate, ulf=(0.01, 0.04), lf=(0.04, 0.15), hf=(0.15, 0.4), vhf=(0.4, 1.))\n",
    "        # hrv_ULF = hrv_freq.loc[0, 'HRV_ULF']  # Feature\n",
    "        # hrv_LF = hrv_freq.loc[0, 'HRV_LF']  # Feature\n",
    "        # hrv_HF = hrv_freq.loc[0, 'HRV_HF']  # Feature\n",
    "        # hrv_VHF = hrv_freq.loc[0, 'HRV_VHF']  # Feature\n",
    "        # hrv_lf_hf_ratio = hrv_freq.loc[0, 'HRV_LFHF']  # Feature\n",
    "        # hrv_f_sum = np.nansum(np.hstack((hrv_ULF, hrv_LF, hrv_HF, hrv_VHF)))\n",
    "        # # TODO: rel_f\n",
    "        # # hrv_rel_f = \n",
    "        # hrv_LFn = hrv_freq.loc[0, 'HRV_LFn']  # Feature\n",
    "        # hrv_HFn = hrv_freq.loc[0, 'HRV_HFn']  # Feature\n",
    "        # ==\n",
    "\n",
    "        ## ECG \n",
    "        w_ecg_cleaned = ecg_cleaned[i: window + i]\n",
    "        _, ecg_info = nk.ecg_peaks(w_ecg_cleaned, sampling_rate=sampling_rate)\n",
    "        w_ecg_rpeaks = ecg_info['ECG_R_Peaks']\n",
    "        ecg_nni = pyhrv.tools.nn_intervals(w_ecg_rpeaks)\n",
    "        # HR\n",
    "        rs_hr = pyhrv.time_domain.hr_parameters(ecg_nni)\n",
    "        hr_mean = rs_hr['hr_mean']  # Feature\n",
    "        hr_std = rs_hr['hr_std']  # Feature\n",
    "        # HRV-time\n",
    "        rs_hrv = pyhrv.time_domain.nni_parameters(ecg_nni)\n",
    "        hrv_mean = rs_hrv['nni_mean']  # Feature\n",
    "        hrv_std = pyhrv.time_domain.sdnn(ecg_nni)['sdnn']  # Feature\n",
    "        rs_nn50 = pyhrv.time_domain.nn50(ecg_nni)\n",
    "        hrv_NN50 = rs_nn50['nn50']  # Feature\n",
    "        hrv_pNN50 = rs_nn50['pnn50']  # Feature\n",
    "        hrv_time = nk.hrv_time(w_ecg_rpeaks, sampling_rate=sampling_rate, show=False)\n",
    "        hrv_TINN = hrv_time.loc[0, 'HRV_TINN']  # Feature\n",
    "        hrv_rms = pyhrv.time_domain.rmssd(ecg_nni)['rmssd']  # Feature\n",
    "        # HRV-freq\n",
    "        hrv_freq = pyhrv.frequency_domain.welch_psd(ecg_nni, fbands={'ulf': (0.01, 0.04), 'vlf': (0.04, 0.15), 'lf': (0.15, 0.4), 'hf': (0.4, 1)}, mode='dev')\n",
    "        # hrv_freq = hrv_freq.as_dict()\n",
    "        hrv_freq = hrv_freq[0]\n",
    "        hrv_ULF = hrv_freq['fft_abs'][0]  # Feature\n",
    "        hrv_LF = hrv_freq['fft_abs'][1]  # Feature\n",
    "        hrv_HF = hrv_freq['fft_abs'][2]  # Feature\n",
    "        hrv_VHF = hrv_freq['fft_abs'][3]  # Feature\n",
    "        hrv_lf_hf_ratio = hrv_freq['fft_ratio']  # Feature\n",
    "        hrv_f_sum = hrv_freq['fft_total']  # Feature\n",
    "        hrv_rel_ULF = hrv_freq['fft_rel'][0]  # Feature\n",
    "        hrv_rel_LF = hrv_freq['fft_rel'][1]  # Feature\n",
    "        hrv_rel_HF = hrv_freq['fft_rel'][2]  # Feature\n",
    "        hrv_rel_VHF = hrv_freq['fft_rel'][3]  # Feature\n",
    "        hrv_LFn = hrv_freq['fft_norm'][0]  # Feature\n",
    "        hrv_HFn = hrv_freq['fft_norm'][1]  # Feature\n",
    "\n",
    "        # EDA\n",
    "        w_eda_data = eda_cleaned[i: window + i]\n",
    "        w_eda_phasic_tonic = eda_phasic_tonic[i: window + i]\n",
    "\n",
    "        eda_mean = np.mean(w_eda_data)  # Feature\n",
    "        eda_std = np.std(w_eda_data)  # Feature\n",
    "        eda_min = np.amin(w_eda_data)  # Feature\n",
    "        eda_max = np.amax(w_eda_data)  # Feature\n",
    "        # dynamic range: https://en.wikipedia.org/wiki/Dynamic_range\n",
    "        eda_slope = get_slope(w_eda_data)  # Feature\n",
    "        eda_drange = eda_max / eda_min  # Feature\n",
    "        eda_scl_mean = np.mean(w_eda_phasic_tonic['EDA_Tonic'])  # Feature\n",
    "        eda_scl_std = np.std(w_eda_phasic_tonic['EDA_Tonic'])  # Feature\n",
    "        eda_scr_mean = np.mean(w_eda_phasic_tonic['EDA_Phasic'])  # Feature\n",
    "        eda_scr_std = np.std(w_eda_phasic_tonic['EDA_Phasic'])  # Feature\n",
    "        eda_corr_scl_t = nk.cor(w_eda_phasic_tonic['EDA_Tonic'], w_eda_phasic_tonic['t'], show=False)  # Feature\n",
    "        \n",
    "        eda_scr_no = eda_scr_peaks['SCR_Peaks'][i: window + i].sum()  # Feature\n",
    "        # Sum amplitudes in SCR signal\n",
    "        ampl = scr_info['SCR_Amplitude'][i: window + i]\n",
    "        eda_ampl_sum = np.sum(ampl[~np.isnan(ampl)])  # Feature\n",
    "        # TODO: \n",
    "        # eda_t_sum = \n",
    "\n",
    "        scr_peaks, scr_properties = scisig.find_peaks(w_eda_phasic_tonic['EDA_Phasic'], height=0)\n",
    "        width_scr = scisig.peak_widths(w_eda_phasic_tonic['EDA_Phasic'], scr_peaks, rel_height=0)\n",
    "        ht_scr = scr_properties['peak_heights']\n",
    "        eda_scr_area = 0.5 * np.matmul(ht_scr, width_scr[1])  # Feature\n",
    "\n",
    "        # EMG\n",
    "        ## 5sec\n",
    "        w_emg_data = emg_filtered_dc[i: window + i]\n",
    "        emg_mean = np.mean(w_emg_data)  # Feature\n",
    "        emg_std = np.std(w_emg_data)  # Feature\n",
    "        emg_min = np.amin(w_emg_data)\n",
    "        emg_max = np.amax(w_emg_data)\n",
    "        emg_drange = emg_max / emg_min  # Feature\n",
    "        emg_absint = np.abs(np.trapz(w_emg_data))  # Feature\n",
    "        emg_median = np.median(w_emg_data)  # Feature\n",
    "        emg_perc_10 = np.percentile(w_emg_data, 10)  # Feature\n",
    "        emg_perc_90 = np.percentile(w_emg_data, 90)  # Feature\n",
    "        emg_peak_freq, emg_mean_freq, emg_median_freq = get_freq_features(w_emg_data)  # Features\n",
    "        # TODO: PSD -> energy in seven bands\n",
    "        # emg_psd = \n",
    "\n",
    "        ## 60 sec\n",
    "        peaks, properties = scisig.find_peaks(emg_filtered[i: window + i], height=0)\n",
    "        emg_peak_no = peaks.shape[0]\n",
    "        emg_peak_amp_mean = np.mean(properties['peak_heights'])  # Feature\n",
    "        emg_peak_amp_std = np.std(properties['peak_heights'])  # Feature\n",
    "        emg_peak_amp_sum = np.sum(properties['peak_heights'])  # Feature\n",
    "        emg_peak_amp_max = np.abs(np.amax(properties['peak_heights']))\n",
    "        # https://www.researchgate.net/post/How_Period_Normalization_and_Amplitude_normalization_are_performed_in_ECG_Signal\n",
    "        emg_peak_amp_norm_sum = np.sum(properties['peak_heights'] / emg_peak_amp_max)  # Feature\n",
    "\n",
    "        # Resp\n",
    "        w_resp_data = resp_processed[i: window + i]\n",
    "        ## Inhalation / Exhalation duration analysis\n",
    "        idx = np.nan\n",
    "        count = 0\n",
    "        duration = dict()\n",
    "        first = True\n",
    "        for j in w_resp_data[~w_resp_data['RSP_Phase'].isnull()]['RSP_Phase'].to_numpy():\n",
    "            if j != idx:\n",
    "                if first:\n",
    "                    idx = int(j)\n",
    "                    duration[1] = []\n",
    "                    duration [0] = []\n",
    "                    first = False\n",
    "                    continue\n",
    "                # print('New value', j, count)\n",
    "                duration[idx].append(count)\n",
    "                idx = int(j)\n",
    "                count = 0 \n",
    "            count += 1\n",
    "        resp_inhal_mean = np.mean(duration[1])  # Feature\n",
    "        resp_inhal_std = np.std(duration[1])  # Feature\n",
    "        resp_exhal_mean = np.mean(duration[0])  # Feature\n",
    "        resp_exhal_std = np.std(duration[0])  # Feature\n",
    "        resp_inhal_duration = w_resp_data['RSP_Phase'][w_resp_data['RSP_Phase'] == 1].count()\n",
    "        resp_exhal_duration = w_resp_data['RSP_Phase'][w_resp_data['RSP_Phase'] == 0].count()\n",
    "        resp_ie_ratio = resp_inhal_duration / resp_exhal_duration  # Feature\n",
    "        resp_duration = resp_inhal_duration + resp_exhal_duration  # Feature\n",
    "        resp_stretch = w_resp_data['RSP_Amplitude'].max() - w_resp_data['RSP_Amplitude'].min()  # Feature\n",
    "        resp_breath_rate = len(duration[1])  # Feature\n",
    "        ## Volume: area under the curve of the inspiration phase on a respiratory cycle\n",
    "        resp_peaks, resp_properties = scisig.find_peaks(w_resp_data['RSP_Clean'], height=0)\n",
    "        resp_width = scisig.peak_widths(w_resp_data['RSP_Clean'], resp_peaks, rel_height=0)\n",
    "        resp_ht = resp_properties['peak_heights']        \n",
    "        resp_volume = 0.5 * np.matmul(resp_ht, resp_width[1])  # Feature\n",
    "\n",
    "        # Temp\n",
    "        w_temp_data = data['Temp'][condition][i: window + i].flatten()\n",
    "        temp_mean = np.mean(w_temp_data)  # Feature\n",
    "        temp_std = np.std(w_temp_data)  # Feature\n",
    "        temp_min = np.amin(w_temp_data)  # Feature\n",
    "        temp_max = np.amax(w_temp_data)  # Feature\n",
    "        temp_drange = temp_max / temp_min  # Feature\n",
    "        temp_slope = get_slope(w_temp_data.ravel())  # Feature\n",
    "\n",
    "\n",
    "        # chest_df_5 = chest_df_5.append({\n",
    "        #     'ACC_x_mean': acc_x_mean, 'ACC_y_mean': acc_y_mean, 'ACC_z_mean': acc_z_mean, 'ACC_xzy_mean': xyz_mean,\n",
    "        #     'ACC_x_std': acc_x_std, 'ACC_y_std': acc_y_std, 'ACC_z_std': acc_z_std, 'ACC_xyz_std': xyz_std,\n",
    "        #     'ACC_x_absint': acc_x_absint, 'ACC_y_absint': acc_y_absint, 'ACC_z_absint': acc_z_absint, 'ACC_xyz_absint': xyz_absint,\n",
    "        #     'ACC_x_peak': acc_x_peak, 'ACC_y_peak': acc_y_peak, 'ACC_z_peak': acc_z_peak,\n",
    "        #     'EMG_mean': emg_mean, 'EMG_std': emg_std, 'EMG_drange': emg_drange, 'EMG_absint': emg_absint, 'EMG_median': emg_median, 'EMG_perc_10': emg_perc_10,\n",
    "        #     'EMG_perc_90': emg_perc_90, 'EMG_peak_freq': emg_peak_freq, 'EMG_mean_freq': emg_mean_freq, 'EMG_median_freq': emg_median_freq\n",
    "        # }, ignore_index=True)\n",
    "\n",
    "        chest_df = chest_df.append({\n",
    "            'ACC_x_mean': acc_x_mean, 'ACC_y_mean': acc_y_mean, 'ACC_z_mean': acc_z_mean, 'ACC_xzy_mean': xyz_mean,\n",
    "            'ACC_x_std': acc_x_std, 'ACC_y_std': acc_y_std, 'ACC_z_std': acc_z_std, 'ACC_xyz_std': xyz_std,\n",
    "            'ACC_x_absint': acc_x_absint, 'ACC_y_absint': acc_y_absint, 'ACC_z_absint': acc_z_absint, 'ACC_xyz_absint': xyz_absint,\n",
    "            'ACC_x_peak': acc_x_peak, 'ACC_y_peak': acc_y_peak, 'ACC_z_peak': acc_z_peak,\n",
    "            'ECG_hr_mean': hr_mean, 'ECG_hr_std': hr_std, 'ECG_hrv_NN50': hrv_NN50, 'ECG_hrv_pNN50': hrv_pNN50, 'ECG_hrv_TINN': hrv_TINN, 'ECG_hrv_RMS': hrv_rms,\n",
    "            'ECG_hrv_ULF': hrv_ULF, 'ECG_hrv_LF': hrv_LF, 'ECG_hrv_HF': hrv_HF, 'ECG_hrv_VHF': hrv_VHF, 'ECG_hrv_LFHF_ratio': hrv_lf_hf_ratio, 'ECG_hrv_f_sum': hrv_f_sum,\n",
    "            'ECG_hrv_rel_ULF': hrv_rel_ULF, 'ECG_hrv_rel_LF': hrv_rel_LF, 'ECG_hrv_rel_HF': hrv_rel_HF, 'ECG_hrv_rel_VHF': hrv_rel_VHF, 'ECG_hrv_LFn': hrv_LFn, 'ECG_hrv_HFn': hrv_HFn,\n",
    "            'EDA_mean': eda_mean, 'EDA_std': eda_std, 'EDA_mean': eda_mean, 'EDA_min': eda_min, 'EDA_max': eda_max, 'EDA_slope': eda_slope,\n",
    "            'EDA_drange': eda_drange, 'EDA_SCL_mean': eda_scl_mean, 'EDA_SCL_std': eda_scl_mean, 'EDA_SCR_mean': eda_scr_mean, 'EDA_SCR_std': eda_scr_std,\n",
    "            'EDA_corr_SCL_t': eda_corr_scl_t, 'EDA_SCR_no': eda_scr_no, 'EDA_ampl_sum': eda_ampl_sum, 'EDA_scr_area': eda_scr_area,\n",
    "            'EMG_mean': emg_mean, 'EMG_std': emg_std, 'EMG_drange': emg_drange, 'EMG_absint': emg_absint, 'EMG_median': emg_median, 'EMG_perc_10': emg_perc_10,\n",
    "            'EMG_perc_90': emg_perc_90, 'EMG_peak_freq': emg_peak_freq, 'EMG_mean_freq': emg_mean_freq, 'EMG_median_freq': emg_median_freq,\n",
    "            'EMG_peak_no': emg_peak_no, 'EMG_peak_amp_mean':  emg_peak_amp_mean, 'EMG_peak_amp_std':  emg_peak_amp_std, 'EMG_peak_amp_sum':  emg_peak_amp_sum,\n",
    "            'EMG_peak_amp_norm_sum':  emg_peak_amp_norm_sum,\n",
    "            'RESP_inhal_mean': resp_inhal_mean, 'RESP_inhal_std': resp_inhal_std, 'RESP_exhal_mean': resp_exhal_mean, 'RESP_exhal_std': resp_exhal_std,\n",
    "            'RESP_ie_ratio': resp_ie_ratio, 'RESP_duration': resp_duration, 'RESP_stretch': resp_stretch, 'RESP_breath_rate': resp_breath_rate, 'RESP_volume': resp_volume,\n",
    "            'TEMP_mean': temp_mean, 'TEMP_std': temp_std, 'TEMP_min': temp_min, 'TEMP_max': temp_max, 'TEMP_drange': temp_drange, 'TEMP_slope': temp_slope\n",
    "        }, ignore_index=True)\n",
    "\n",
    "\n",
    "        # index += 1\n",
    "        # if index % 10 == 0:\n",
    "        #     break\n",
    "    \n",
    "    print('Elapsed Process', condition.shape[0], str(timedelta(seconds=time.time() - init)))\n",
    "    return chest_df, chest_df_5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7j0ECbcblDDb"
   },
   "source": [
    "## Chest-worn device - Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wf1aiK2O0oTH"
   },
   "outputs": [],
   "source": [
    "def process_subject(subject_data, cond_to_process, max_workers=6):\n",
    "    rs = dict()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_label = {executor.submit(compute_features, subject_data, cond): label for label, cond in cond_to_process}\n",
    "        for future in concurrent.futures.as_completed(future_to_label):\n",
    "            label = future_to_label[future]\n",
    "            try:\n",
    "                data, _ = future.result()\n",
    "                print(label, data.shape)\n",
    "                rs[label] = data\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (label, exc))\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "zu_aIQ-3lFsM",
    "outputId": "b30a8d40-579f-4569-9909-3a585503857a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject S7\n",
      "{'ACC': 3666600, 'ECG': 3666600, 'EMG': 3666600, 'EDA': 3666600, 'Temp': 3666600, 'Resp': 3666600}\n",
      "Baseline: (830200, 1)\n",
      "Stress: (448000, 1)\n",
      "Amusement: (260401, 1)\n",
      "Elapsed Preprocess 0:00:03.382145\n",
      "Elapsed Preprocess 0:00:04.232839\n",
      "Elapsed Preprocess 0:00:10.452032\n",
      "Elapsed Process 260401 0:02:40.979362\n",
      "amusement (1249, 77)\n",
      "Elapsed Process 448000 0:04:29.071290\n",
      "stress (2320, 77)\n",
      "Elapsed Process 830200 0:07:14.459127\n",
      "baseline (4504, 77)\n",
      "CPU times: user 38min 59s, sys: 7min 4s, total: 46min 4s\n",
      "Wall time: 7min 24s\n",
      "Generated dataset for S7 (8073, 79)\n",
      "Subject S8\n",
      "{'ACC': 3826200, 'ECG': 3826200, 'EMG': 3826200, 'EDA': 3826200, 'Temp': 3826200, 'Resp': 3826200}\n",
      "Baseline: (818300, 1)\n",
      "Stress: (469000, 1)\n",
      "Amusement: (258999, 1)\n",
      "Elapsed Preprocess 0:00:02.288148\n",
      "Elapsed Preprocess 0:00:02.823671\n",
      "Elapsed Preprocess 0:00:04.078425\n",
      "Elapsed Process 258999 0:02:34.723430\n",
      "amusement (1240, 77)\n",
      "Elapsed Process 469000 0:04:38.775093\n",
      "stress (2440, 77)\n",
      "Elapsed Process 818300 0:07:15.700035\n",
      "baseline (4436, 77)\n",
      "CPU times: user 38min 42s, sys: 7min 4s, total: 45min 46s\n",
      "Wall time: 7min 19s\n",
      "Generated dataset for S8 (8116, 79)\n",
      "Subject S9\n",
      "{'ACC': 3656100, 'ECG': 3656100, 'EMG': 3656100, 'EDA': 3656100, 'Temp': 3656100, 'Resp': 3656100}\n",
      "Baseline: (826000, 1)\n",
      "Stress: (451500, 1)\n",
      "Amusement: (260400, 1)\n",
      "Elapsed Preprocess 0:00:01.157067\n",
      "Elapsed Preprocess 0:00:01.813730\n",
      "Elapsed Preprocess 0:00:03.400825\n",
      "Elapsed Process 260400 0:02:47.912457\n",
      "amusement (1248, 77)\n",
      "Elapsed Process 451500 0:04:37.162202\n",
      "stress (2340, 77)\n",
      "Elapsed Process 826000 0:07:29.823341\n",
      "baseline (4480, 77)\n",
      "CPU times: user 39min 43s, sys: 7min 25s, total: 47min 9s\n",
      "Wall time: 7min 33s\n",
      "Generated dataset for S9 (8068, 79)\n"
     ]
    }
   ],
   "source": [
    "subjects = ['S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S13', 'S14', 'S15', 'S16', 'S17']\n",
    "for subject in subjects:\n",
    "    print('Subject', subject)\n",
    "    chest_data_dict = obj_data[subject].get_chest_data()\n",
    "    labels = obj_data[subject].get_labels()\n",
    "    chest_dict_length = {key: len(value) for key, value in chest_data_dict.items()}\n",
    "    print(chest_dict_length)\n",
    "\n",
    "    # Get labels\n",
    "    baseline = np.asarray([idx for idx,val in enumerate(labels) if val == 1])\n",
    "    stress = np.asarray([idx for idx,val in enumerate(labels) if val == 2])\n",
    "    amusement = np.asarray([idx for idx,val in enumerate(labels) if val == 3])\n",
    "\n",
    "    print(\"Baseline:\", chest_data_dict['ECG'][baseline].shape)\n",
    "    print(\"Stress:\", chest_data_dict['ECG'][stress].shape)\n",
    "    print(\"Amusement:\", chest_data_dict['ECG'][amusement].shape)\n",
    "\n",
    "    # Process Subject\n",
    "    to_process = zip(['baseline', 'stress', 'amusement'], [baseline, stress, amusement])\n",
    "    # to_process = zip(['baseline'], [baseline])\n",
    "    %time subject_data = process_subject(chest_data_dict, cond_to_process=to_process)\n",
    "\n",
    "    ## Labeling\n",
    "    subject_data['baseline']['label'] = 1\n",
    "    subject_data['baseline']['subject'] = subject\n",
    "    subject_data['stress']['label'] = 2\n",
    "    subject_data['stress']['subject'] = subject\n",
    "    subject_data['amusement']['label'] = 3\n",
    "    subject_data['amusement']['subject'] = subject\n",
    "    ## Storing\n",
    "    dfs = [v for k, v in subject_data.items()]\n",
    "    df_subject = pd.concat(dfs)\n",
    "    print('Generated dataset for', subject, df_subject.shape)\n",
    "    df_subject.head()\n",
    "    df_subject.reset_index().to_feather(f'{subject}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files If running in Google Colab\n",
    "# from google.colab import files\n",
    "# [files.download(file) for file in os.listdir('.') if file.endswith('feather')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QqkeZuf_WNv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPNwvrDZMkTVXfJiCdmJhiL",
   "collapsed_sections": [
    "PSRQ7dUs33ru",
    "3TYvqbCW1wtz",
    "_zR5vyy7gJkk",
    "sOdJAQwfgzaJ",
    "6oGR_62zhNcm",
    "jr5fIfCunhaO",
    "qKdtGCQH3Z2l"
   ],
   "include_colab_link": true,
   "name": "WESAD - Data Exploration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
