{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/santteegt/om-fol-timeseries/blob/master/WESAD_Data_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPBxt5U64v8n"
   },
   "source": [
    "# WESAD - A Multimodal Dataset for Wearable Stress and Affect Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scMGFUBL1cVY"
   },
   "source": [
    "## Requires Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "vPwtauZv0M-M",
    "outputId": "7d9022f3-77c8-4200-e391-0f2863057120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neurokit2 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (0.0.36)\n",
      "Requirement already satisfied: pyhrv in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: matplotlib in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from neurokit2) (3.2.1)\n",
      "Requirement already satisfied: pandas in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from neurokit2) (1.0.3)\n",
      "Requirement already satisfied: numpy in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from neurokit2) (1.18.4)\n",
      "Requirement already satisfied: scipy in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from neurokit2) (1.4.1)\n",
      "Requirement already satisfied: sklearn in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from neurokit2) (0.0)\n",
      "Requirement already satisfied: nolds in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from pyhrv) (0.5.2)\n",
      "Requirement already satisfied: biosppy in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from pyhrv) (0.6.1)\n",
      "Requirement already satisfied: spectrum in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from pyhrv) (0.7.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from matplotlib->neurokit2) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from matplotlib->neurokit2) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from matplotlib->neurokit2) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from matplotlib->neurokit2) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from pandas->neurokit2) (2020.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from sklearn->neurokit2) (0.23.0)\n",
      "Requirement already satisfied: setuptools in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from nolds->pyhrv) (46.1.3.post20200330)\n",
      "Requirement already satisfied: future in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from nolds->pyhrv) (0.18.2)\n",
      "Requirement already satisfied: six in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from biosppy->pyhrv) (1.14.0)\n",
      "Requirement already satisfied: bidict in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from biosppy->pyhrv) (0.19.0)\n",
      "Requirement already satisfied: shortuuid in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from biosppy->pyhrv) (1.0.1)\n",
      "Requirement already satisfied: h5py in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from biosppy->pyhrv) (2.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from scikit-learn->sklearn->neurokit2) (2.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/santteegt/anaconda3/envs/om_research/lib/python3.6/site-packages (from scikit-learn->sklearn->neurokit2) (0.15.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install neurokit2 pyhrv pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REMGlK_Z3zq6"
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from datetime import timedelta\n",
    "\n",
    "import gzip\n",
    "import logging\n",
    "import matplotlib as plt\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyhrv\n",
    "import scipy.signal as scisig\n",
    "import scipy.stats\n",
    "import shutil\n",
    "import time\n",
    "from urllib.request import Request, urlopen\n",
    "import zipfile\n",
    "\n",
    "import cvxEDA\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 7]  # Bigger images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "zuYTKZ-I1Mcb",
    "outputId": "2b2e7e05-3a94-44f7-ed14-3c1014aed66d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('cvxEDA.py'):\n",
    "    !wget https://raw.githubusercontent.com/lciti/cvxEDA/master/src/cvxEDA.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "yLIJiqRh0H21",
    "outputId": "b4934fb3-6fe8-4426-a889-20e09b9b4f55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2224\r\n",
      "-rw-r--r--  1 santteegt  staff       20 Jun 11 10:10 README.md\r\n",
      "-rw-r--r--  1 santteegt  staff  1125495 Jun 11 10:33 WESAD_Data_Exploration.ipynb\r\n",
      "drwxr-xr-x  3 santteegt  staff       96 Jun 11 10:13 \u001b[34m__pycache__\u001b[m\u001b[m\r\n",
      "-rw-r--r--  1 santteegt  staff     5876 Jun 11 10:12 cvxEDA.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PSRQ7dUs33ru"
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FkU_oqlJh9Jm"
   },
   "outputs": [],
   "source": [
    "class WesadDataLoader():\n",
    "    \"\"\"Downloads and load data from the WESAD dataset\n",
    "        \n",
    "        Source URI: https://uni-siegen.sciebo.de/s/pYjSgfOVs6Ntahr/download\n",
    "    \"\"\"\n",
    "    \n",
    "    LABEL = 'label'\n",
    "    SIGNAL = 'signal'\n",
    "    SUBJECT = 'subject'\n",
    "    \n",
    "    WRIST_DEV = 'wrist'\n",
    "    CHEST_DEV = 'chest'\n",
    "    \n",
    "    DATASET_NAME = 'WESAD'\n",
    "    DATASET_URI = 'https://uni-siegen.sciebo.de/s/pYjSgfOVs6Ntahr/download'\n",
    "    \n",
    "    def __init__(self, subject, basepath='.'):\n",
    "        self.logger = logging.getLogger(WesadDataLoader.__name__)\n",
    "        self.logger.info('Init...')\n",
    "        self.chest_modalities = ['ACC', 'ECG', 'EDA', 'EMG', 'Resp', 'Temp']\n",
    "        self.wrist_modalities = ['ACC', 'BVP', 'EDA', 'TEMP']\n",
    "        self.mod_samp_rate = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4, 'chest': 700}  # Hz\n",
    "        WesadDataLoader.download(basepath)\n",
    "        basepath = os.path.join(os.path.abspath(basepath), WesadDataLoader.DATASET_NAME, subject)\n",
    "        if not os.path.isdir(basepath):\n",
    "            raise Exception(f'Dataset path does not exist or is not a directory: {basepath}')\n",
    "        data_file = os.path.join(basepath, f'{subject}.pkl')\n",
    "        if not os.path.exists(data_file):\n",
    "            raise Exception(f'Data file does not exists: {data_file}')\n",
    "#         with open(subject + '.pkl', 'rb') as file:\n",
    "#             data = pickle.load(file, encoding='latin1')\n",
    "        self.data = pd.read_pickle(data_file)\n",
    "    \n",
    "    @staticmethod\n",
    "    def download(basepath):\n",
    "        filename = os.path.join(os.path.abspath(basepath), f'{WesadDataLoader.DATASET_NAME}.zip')\n",
    "        data_folder = os.path.join(os.path.abspath(basepath), WesadDataLoader.DATASET_NAME)\n",
    "        if not os.path.isdir(data_folder) and not os.path.exists(filename):\n",
    "            print('Downloading dataset...')\n",
    "            start = time.time()\n",
    "            response = urlopen(WesadDataLoader.DATASET_URI)\n",
    "            print(f'Elapsed: {time.time() - start} secs')\n",
    "        if not os.path.isdir(data_folder):\n",
    "            with open(filename, 'wb') as out_file:\n",
    "                print('Saving dataset locally...')\n",
    "                start = time.time()\n",
    "                shutil.copyfileobj(response, out_file)\n",
    "            out_file.close()\n",
    "            print(f'Elapsed: {time.time() - start} secs')\n",
    "            start = time.time()\n",
    "            while not zipfile.is_zipfile(filename):\n",
    "                print('Wait..')\n",
    "            print('Found Zip...')\n",
    "            print(f'Elapsed: {time.time() - start} secs')\n",
    "            with zipfile.ZipFile(filename) as zf:\n",
    "                print('Extracting files...')\n",
    "                start = time.time()\n",
    "                zf.extractall()\n",
    "            print(f'Elapsed: {time.time() - start} secs')\n",
    "            print('Done!')\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.data[WesadDataLoader.LABEL]\n",
    "\n",
    "    def get_wrist_data(self):\n",
    "        \"\"\"\"\"\"\n",
    "        #label = self.data[self.keys[0]]\n",
    "#         assert subject == self.data[self.keys[1]]\n",
    "        signal = self.data[WesadDataLoader.SIGNAL]\n",
    "        wrist_data = signal[WesadDataLoader.WRIST_DEV]\n",
    "        # Adding Resp modality from chest device\n",
    "        wrist_data.update({'Resp': self.data[WesadDataLoader.SIGNAL][WesadDataLoader.CHEST_DEV]['Resp']})\n",
    "        return wrist_data\n",
    "\n",
    "    def get_chest_data(self):\n",
    "        \"\"\"\"\"\"\n",
    "        signal = self.data[WesadDataLoader.SIGNAL]\n",
    "        chest_data = signal[WesadDataLoader.CHEST_DEV]\n",
    "        return chest_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXQ_4tv137W2"
   },
   "source": [
    "## Data Exploration - Initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "qS5OCLaidPcu",
    "outputId": "5ff81558-0b7f-4158-8d18-0f1e6bc43cd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.8 s, sys: 27.2 s, total: 1min 20s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "BASE_PATH = './'\n",
    "# WesadDataLoader.download('.')\n",
    "DATASET_PATH = os.path.join(BASE_PATH, WesadDataLoader.DATASET_NAME)\n",
    "subjects = [dir_ for dir_ in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, dir_))]\n",
    "# subjects = ['S3']\n",
    "obj_data = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    obj_data[subject] = WesadDataLoader(subject=subject, basepath=BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "1ASOr67U9Eke",
    "outputId": "cea3f8e1-99ac-4247-f798-673658deb793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects dict_keys(['S5', 'S2', 'S3', 'S4', 'S17', 'S10', 'S11', 'S16', 'S8', 'S6', 'S7', 'S9', 'S13', 'S14', 'S15'])\n",
      "Subject S5 8148\n",
      "Subject S2 7764\n",
      "Subject S3 7900\n",
      "Subject S4 7941\n",
      "Subject S17 8384\n",
      "Subject S10 8388\n",
      "Subject S11 8192\n",
      "Subject S16 8165\n",
      "Subject S8 8116\n",
      "Subject S6 8088\n",
      "Subject S7 8073\n",
      "Subject S9 8068\n",
      "Subject S13 8185\n",
      "Subject S14 8189\n",
      "Subject S15 8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23206404, 121813)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dataset size\n",
    "sampling_rate=700\n",
    "window_size=60\n",
    "window_shift=0.25\n",
    "\n",
    "baseline_rec = 0\n",
    "stress_rec = 0\n",
    "amusement_rec = 0\n",
    "total_segmented = 0\n",
    "print('Subjects', obj_data.keys())\n",
    "for sub in obj_data.keys():\n",
    "    data = obj_data[sub].get_chest_data()\n",
    "    labels = obj_data[sub].get_labels()\n",
    "    baseline = np.asarray([idx for idx,val in enumerate(labels) if val == 1])\n",
    "    stress = np.asarray([idx for idx,val in enumerate(labels) if val == 2])\n",
    "    amusement = np.asarray([idx for idx,val in enumerate(labels) if val == 3])\n",
    "\n",
    "    baseline_rec += baseline.shape[0]\n",
    "    stress_rec += stress.shape[0]\n",
    "    amusement_rec += amusement.shape[0]\n",
    "    conditions = [baseline, stress, amusement]\n",
    "    \n",
    "    subtotal = 0\n",
    "    for cond in conditions:\n",
    "        subtotal += len(list(range(0, data['ACC'][cond].shape[0] - (sampling_rate * window_size), int(sampling_rate * window_shift))))\n",
    "    print('Subject', sub, subtotal)\n",
    "    total_segmented += subtotal\n",
    "\n",
    "(baseline_rec + stress_rec + amusement_rec), total_segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2wH1VOlIOTX"
   },
   "outputs": [],
   "source": [
    "def get_slope(series):\n",
    "    linreg = scipy.stats.linregress(np.arange(len(series)), series )\n",
    "    slope = linreg[0]\n",
    "    return slope\n",
    "\n",
    "\n",
    "def get_freq_features(series):\n",
    "    # Peak frequency is simply the frequency of maximum power\n",
    "    f, Pxx = scisig.periodogram(series) # Estimate power spectral density (PSD) using a periodogram\n",
    "    psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "    peak_freq = psd_dict[max(psd_dict.keys())]\n",
    "    # Mean freq: http://luscinia.sourceforge.net/page26/page35/page35.html\n",
    "    mean_freq = np.dot(Pxx, f) / np.sum(Pxx)\n",
    "    avg_power = np.sum(Pxx) / 2\n",
    "    # Median freq: http://luscinia.sourceforge.net/page26/page36/page36.html\n",
    "    median_freq = f[(np.cumsum(f) > avg_power).argmax()]\n",
    "\n",
    "    return peak_freq, mean_freq, median_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8m_8eOSjmoJ"
   },
   "source": [
    "### Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVvvC6NAbn30"
   },
   "outputs": [],
   "source": [
    "def compute_features(data, condition, sampling_rate=700, window_size=60, window_shift=0.25):\n",
    "\n",
    "    index = 0\n",
    "    init = time.time()\n",
    "\n",
    "    # data cleaning\n",
    "    ## ECG\n",
    "    ecg_cleaned = nk.ecg_clean(data[\"ECG\"][condition].flatten(), sampling_rate=sampling_rate)\n",
    "    ## == OLD\n",
    "    # ecg_rpeaks, _ = nk.ecg_peaks(ecg_cleaned, sampling_rate=sampling_rate)\n",
    "    # ecg_hr = nk.signal_rate(ecg_rpeaks, sampling_rate=sampling_rate)\n",
    "    ## ==\n",
    "    ## EDA\n",
    "    ## 5Hz lowpass filter\n",
    "    eda_highcut = 5\n",
    "    eda_filtered = nk.signal_filter(data['EDA'][condition].flatten(), sampling_rate=sampling_rate, highcut=eda_highcut)\n",
    "    eda_cleaned = nk.standardize(eda_filtered)\n",
    "    # TODO: not sure about the approach. cvxeda takes longer periods\n",
    "    # phasic_tonic = nk.eda_phasic(cleaned, sampling_rate=700, method='cvxeda')\n",
    "    eda_phasic_tonic = nk.eda_phasic(eda_cleaned, sampling_rate=sampling_rate)\n",
    "    eda_phasic_tonic['t'] = [(1 / sampling_rate) * i for i in range(eda_phasic_tonic.shape[0])]\n",
    "    eda_scr_peaks, scr_info = nk.eda_peaks(eda_phasic_tonic['EDA_Phasic'], sampling_rate=sampling_rate)\n",
    "    ## EMG\n",
    "    ## For 5 sec window signal\n",
    "    ## More on DC Bias https://www.c-motion.com/v3dwiki/index.php/EMG:_Removing_DC_Bias\n",
    "    emg_lowcut = 50\n",
    "    emg_filtered_dc = nk.signal_filter(data['EMG'][condition].flatten(), sampling_rate=sampling_rate, lowcut=emg_lowcut)\n",
    "    # OR 100 Hz highpass Butterworth filter followed by a constant detrending\n",
    "    # filtered_dc = nk.emg_clean(chest_data_dict['EMG'][baseline].flatten(), sampling_rate=700)\n",
    "    ## For 60 sec window signal\n",
    "    # 50Hz lowpass filter\n",
    "    emg_highcut = 50\n",
    "    emg_filtered = nk.signal_filter(data['EMG'][condition].flatten(), sampling_rate=sampling_rate, highcut=emg_highcut)\n",
    "    ## Resp\n",
    "    ## Method biosppy important to appply bandpass filter 0.1 - 0.35 Hz\n",
    "    resp_processed, _ = nk.rsp_process(data['Resp'][condition].flatten(), sampling_rate=sampling_rate, method='biosppy')\n",
    "\n",
    "    print('Elapsed Preprocess', str(timedelta(seconds=time.time() - init)))\n",
    "    init = time.time()\n",
    "\n",
    "    chest_df_5 = pd.DataFrame() # For 5 sec window size\n",
    "    chest_df = pd.DataFrame()\n",
    "\n",
    "    window = int(sampling_rate * window_size)\n",
    "    for i in range(0, data['ACC'][condition].shape[0] - window, int(sampling_rate * window_shift)):\n",
    "\n",
    "        # ACC\n",
    "        w_acc_data = data['ACC'][condition][i: window + i]\n",
    "        acc_x_mean, acc_y_mean, acc_z_mean = np.mean(w_acc_data, axis=0)  # Feature\n",
    "        acc_x_std, acc_y_std, acc_z_std = np.std(w_acc_data, axis=0)  # Feature\n",
    "        acc_x_peak, acc_y_peak, acc_z_peak = np.amax(w_acc_data, axis=0)  # Feature\n",
    "        acc_x_absint, acc_y_absint, acc_z_absint = np.abs(np.trapz(w_acc_data, axis=0))  # Feature\n",
    "        xyz = np.sum(w_acc_data, axis=0)\n",
    "        xyz_mean = np.mean(xyz)  # Feature\n",
    "        xyz_std = np.std(xyz)  # Feature\n",
    "        xyz_absint = np.abs(np.trapz(xyz))  # Feature\n",
    "\n",
    "\n",
    "        # == OLD\n",
    "        # ## ECG\n",
    "        # w_ecg_rpeaks = ecg_rpeaks[i: window + i]\n",
    "        # # HR\n",
    "        # w_ecg_hr = ecg_hr[i: window + i]\n",
    "        # hr_mean = np.mean(w_ecg_hr)  # Feature\n",
    "        # hr_std = np.std(w_ecg_hr)  # Feature\n",
    "        # # HRV Time-domain Indices\n",
    "        # # HRV_MeanNN\n",
    "        # # HRV_SDNN\n",
    "        # # HRV_pNN50\n",
    "        # # HRV_RMSSD -> Root mean square of the HRV\n",
    "        # # HRV_HTI -> Triangular interpolation index\n",
    "        # hrv_time = nk.hrv_time(w_ecg_rpeaks, sampling_rate=sampling_rate, show=False)\n",
    "        # hrv_mean = hrv_time.loc[0, 'HRV_MeanNN']  # Feature\n",
    "        # hrv_std = hrv_time.loc[0, 'HRV_SDNN']  # Feature\n",
    "        # # TODO: NN50\n",
    "        # # hrv_NN50 = \n",
    "        # hrv_pNN50 = hrv_time.loc[0, 'HRV_pNN50']  # Feature\n",
    "        # hrv_TINN = hrv_time.loc[0, 'HRV_HTI']  # Feature\n",
    "        # hrv_rms = hrv_time.loc[0, 'HRV_RMSSD']  # Feature\n",
    "\n",
    "        # # HRV Frequency-domain Indices\n",
    "        # # TODO: get NaN values within windows (*)\n",
    "        # # HRV_ULF *\n",
    "        # # HRV_LF *\n",
    "        # # HRV_HF \n",
    "        # # HRV_VHF\n",
    "        # # HRV_LFHF - Ratio LF/HF *\n",
    "        # # HRV_LFn *\n",
    "        # # HRV_HFn\n",
    "        # hrv_freq = nk.hrv_frequency(w_ecg_rpeaks, sampling_rate=sampling_rate, ulf=(0.01, 0.04), lf=(0.04, 0.15), hf=(0.15, 0.4), vhf=(0.4, 1.))\n",
    "        # hrv_ULF = hrv_freq.loc[0, 'HRV_ULF']  # Feature\n",
    "        # hrv_LF = hrv_freq.loc[0, 'HRV_LF']  # Feature\n",
    "        # hrv_HF = hrv_freq.loc[0, 'HRV_HF']  # Feature\n",
    "        # hrv_VHF = hrv_freq.loc[0, 'HRV_VHF']  # Feature\n",
    "        # hrv_lf_hf_ratio = hrv_freq.loc[0, 'HRV_LFHF']  # Feature\n",
    "        # hrv_f_sum = np.nansum(np.hstack((hrv_ULF, hrv_LF, hrv_HF, hrv_VHF)))\n",
    "        # # TODO: rel_f\n",
    "        # # hrv_rel_f = \n",
    "        # hrv_LFn = hrv_freq.loc[0, 'HRV_LFn']  # Feature\n",
    "        # hrv_HFn = hrv_freq.loc[0, 'HRV_HFn']  # Feature\n",
    "        # ==\n",
    "\n",
    "        ## ECG \n",
    "        w_ecg_cleaned = ecg_cleaned[i: window + i]\n",
    "        _, ecg_info = nk.ecg_peaks(w_ecg_cleaned, sampling_rate=sampling_rate)\n",
    "        w_ecg_rpeaks = ecg_info['ECG_R_Peaks']\n",
    "        ecg_nni = pyhrv.tools.nn_intervals(w_ecg_rpeaks)\n",
    "        # HR\n",
    "        rs_hr = pyhrv.time_domain.hr_parameters(ecg_nni)\n",
    "        hr_mean = rs_hr['hr_mean']  # Feature\n",
    "        hr_std = rs_hr['hr_std']  # Feature\n",
    "        # HRV-time\n",
    "        rs_hrv = pyhrv.time_domain.nni_parameters(ecg_nni)\n",
    "        hrv_mean = rs_hrv['nni_mean']  # Feature\n",
    "        hrv_std = pyhrv.time_domain.sdnn(ecg_nni)['sdnn']  # Feature\n",
    "        rs_nn50 = pyhrv.time_domain.nn50(ecg_nni)\n",
    "        hrv_NN50 = rs_nn50['nn50']  # Feature\n",
    "        hrv_pNN50 = rs_nn50['pnn50']  # Feature\n",
    "        hrv_time = nk.hrv_time(w_ecg_rpeaks, sampling_rate=sampling_rate, show=False)\n",
    "        hrv_TINN = hrv_time.loc[0, 'HRV_TINN']  # Feature\n",
    "        hrv_rms = pyhrv.time_domain.rmssd(ecg_nni)['rmssd']  # Feature\n",
    "        # HRV-freq\n",
    "        hrv_freq = pyhrv.frequency_domain.welch_psd(ecg_nni, fbands={'ulf': (0.01, 0.04), 'vlf': (0.04, 0.15), 'lf': (0.15, 0.4), 'hf': (0.4, 1)}, mode='dev')\n",
    "        # hrv_freq = hrv_freq.as_dict()\n",
    "        hrv_freq = hrv_freq[0]\n",
    "        hrv_ULF = hrv_freq['fft_abs'][0]  # Feature\n",
    "        hrv_LF = hrv_freq['fft_abs'][1]  # Feature\n",
    "        hrv_HF = hrv_freq['fft_abs'][2]  # Feature\n",
    "        hrv_VHF = hrv_freq['fft_abs'][3]  # Feature\n",
    "        hrv_lf_hf_ratio = hrv_freq['fft_ratio']  # Feature\n",
    "        hrv_f_sum = hrv_freq['fft_total']  # Feature\n",
    "        hrv_rel_ULF = hrv_freq['fft_rel'][0]  # Feature\n",
    "        hrv_rel_LF = hrv_freq['fft_rel'][1]  # Feature\n",
    "        hrv_rel_HF = hrv_freq['fft_rel'][2]  # Feature\n",
    "        hrv_rel_VHF = hrv_freq['fft_rel'][3]  # Feature\n",
    "        hrv_LFn = hrv_freq['fft_norm'][0]  # Feature\n",
    "        hrv_HFn = hrv_freq['fft_norm'][1]  # Feature\n",
    "\n",
    "        # EDA\n",
    "        w_eda_data = eda_cleaned[i: window + i]\n",
    "        w_eda_phasic_tonic = eda_phasic_tonic[i: window + i]\n",
    "\n",
    "        eda_mean = np.mean(w_eda_data)  # Feature\n",
    "        eda_std = np.std(w_eda_data)  # Feature\n",
    "        eda_min = np.amin(w_eda_data)  # Feature\n",
    "        eda_max = np.amax(w_eda_data)  # Feature\n",
    "        # dynamic range: https://en.wikipedia.org/wiki/Dynamic_range\n",
    "        eda_slope = get_slope(w_eda_data)  # Feature\n",
    "        eda_drange = eda_max / eda_min  # Feature\n",
    "        eda_scl_mean = np.mean(w_eda_phasic_tonic['EDA_Tonic'])  # Feature\n",
    "        eda_scl_std = np.std(w_eda_phasic_tonic['EDA_Tonic'])  # Feature\n",
    "        eda_scr_mean = np.mean(w_eda_phasic_tonic['EDA_Phasic'])  # Feature\n",
    "        eda_scr_std = np.std(w_eda_phasic_tonic['EDA_Phasic'])  # Feature\n",
    "        eda_corr_scl_t = nk.cor(w_eda_phasic_tonic['EDA_Tonic'], w_eda_phasic_tonic['t'], show=False)  # Feature\n",
    "        \n",
    "        eda_scr_no = eda_scr_peaks['SCR_Peaks'][i: window + i].sum()  # Feature\n",
    "        # Sum amplitudes in SCR signal\n",
    "        ampl = scr_info['SCR_Amplitude'][i: window + i]\n",
    "        eda_ampl_sum = np.sum(ampl[~np.isnan(ampl)])  # Feature\n",
    "        # TODO: \n",
    "        # eda_t_sum = \n",
    "\n",
    "        scr_peaks, scr_properties = scisig.find_peaks(w_eda_phasic_tonic['EDA_Phasic'], height=0)\n",
    "        width_scr = scisig.peak_widths(w_eda_phasic_tonic['EDA_Phasic'], scr_peaks, rel_height=0)\n",
    "        ht_scr = scr_properties['peak_heights']\n",
    "        eda_scr_area = 0.5 * np.matmul(ht_scr, width_scr[1])  # Feature\n",
    "\n",
    "        # EMG\n",
    "        ## 5sec\n",
    "        w_emg_data = emg_filtered_dc[i: window + i]\n",
    "        emg_mean = np.mean(w_emg_data)  # Feature\n",
    "        emg_std = np.std(w_emg_data)  # Feature\n",
    "        emg_min = np.amin(w_emg_data)\n",
    "        emg_max = np.amax(w_emg_data)\n",
    "        emg_drange = emg_max / emg_min  # Feature\n",
    "        emg_absint = np.abs(np.trapz(w_emg_data))  # Feature\n",
    "        emg_median = np.median(w_emg_data)  # Feature\n",
    "        emg_perc_10 = np.percentile(w_emg_data, 10)  # Feature\n",
    "        emg_perc_90 = np.percentile(w_emg_data, 90)  # Feature\n",
    "        emg_peak_freq, emg_mean_freq, emg_median_freq = get_freq_features(w_emg_data)  # Features\n",
    "        # TODO: PSD -> energy in seven bands\n",
    "        # emg_psd = \n",
    "\n",
    "        ## 60 sec\n",
    "        peaks, properties = scisig.find_peaks(emg_filtered[i: window + i], height=0)\n",
    "        emg_peak_no = peaks.shape[0]\n",
    "        emg_peak_amp_mean = np.mean(properties['peak_heights'])  # Feature\n",
    "        emg_peak_amp_std = np.std(properties['peak_heights'])  # Feature\n",
    "        emg_peak_amp_sum = np.sum(properties['peak_heights'])  # Feature\n",
    "        emg_peak_amp_max = np.abs(np.amax(properties['peak_heights']))\n",
    "        # https://www.researchgate.net/post/How_Period_Normalization_and_Amplitude_normalization_are_performed_in_ECG_Signal\n",
    "        emg_peak_amp_norm_sum = np.sum(properties['peak_heights'] / emg_peak_amp_max)  # Feature\n",
    "\n",
    "        # Resp\n",
    "        w_resp_data = resp_processed[i: window + i]\n",
    "        ## Inhalation / Exhalation duration analysis\n",
    "        idx = np.nan\n",
    "        count = 0\n",
    "        duration = dict()\n",
    "        first = True\n",
    "        for j in w_resp_data[~w_resp_data['RSP_Phase'].isnull()]['RSP_Phase'].to_numpy():\n",
    "            if j != idx:\n",
    "                if first:\n",
    "                    idx = int(j)\n",
    "                    duration[1] = []\n",
    "                    duration [0] = []\n",
    "                    first = False\n",
    "                    continue\n",
    "                # print('New value', j, count)\n",
    "                duration[idx].append(count)\n",
    "                idx = int(j)\n",
    "                count = 0 \n",
    "            count += 1\n",
    "        resp_inhal_mean = np.mean(duration[1])  # Feature\n",
    "        resp_inhal_std = np.std(duration[1])  # Feature\n",
    "        resp_exhal_mean = np.mean(duration[0])  # Feature\n",
    "        resp_exhal_std = np.std(duration[0])  # Feature\n",
    "        resp_inhal_duration = w_resp_data['RSP_Phase'][w_resp_data['RSP_Phase'] == 1].count()\n",
    "        resp_exhal_duration = w_resp_data['RSP_Phase'][w_resp_data['RSP_Phase'] == 0].count()\n",
    "        resp_ie_ratio = resp_inhal_duration / resp_exhal_duration  # Feature\n",
    "        resp_duration = resp_inhal_duration + resp_exhal_duration  # Feature\n",
    "        resp_stretch = w_resp_data['RSP_Amplitude'].max() - w_resp_data['RSP_Amplitude'].min()  # Feature\n",
    "        resp_breath_rate = len(duration[1])  # Feature\n",
    "        ## Volume: area under the curve of the inspiration phase on a respiratory cycle\n",
    "        resp_peaks, resp_properties = scisig.find_peaks(w_resp_data['RSP_Clean'], height=0)\n",
    "        resp_width = scisig.peak_widths(w_resp_data['RSP_Clean'], resp_peaks, rel_height=0)\n",
    "        resp_ht = resp_properties['peak_heights']        \n",
    "        resp_volume = 0.5 * np.matmul(resp_ht, resp_width[1])  # Feature\n",
    "\n",
    "        # Temp\n",
    "        w_temp_data = data['Temp'][condition][i: window + i].flatten()\n",
    "        temp_mean = np.mean(w_temp_data)  # Feature\n",
    "        temp_std = np.std(w_temp_data)  # Feature\n",
    "        temp_min = np.amin(w_temp_data)  # Feature\n",
    "        temp_max = np.amax(w_temp_data)  # Feature\n",
    "        temp_drange = temp_max / temp_min  # Feature\n",
    "        temp_slope = get_slope(w_temp_data.ravel())  # Feature\n",
    "\n",
    "\n",
    "        # chest_df_5 = chest_df_5.append({\n",
    "        #     'ACC_x_mean': acc_x_mean, 'ACC_y_mean': acc_y_mean, 'ACC_z_mean': acc_z_mean, 'ACC_xzy_mean': xyz_mean,\n",
    "        #     'ACC_x_std': acc_x_std, 'ACC_y_std': acc_y_std, 'ACC_z_std': acc_z_std, 'ACC_xyz_std': xyz_std,\n",
    "        #     'ACC_x_absint': acc_x_absint, 'ACC_y_absint': acc_y_absint, 'ACC_z_absint': acc_z_absint, 'ACC_xyz_absint': xyz_absint,\n",
    "        #     'ACC_x_peak': acc_x_peak, 'ACC_y_peak': acc_y_peak, 'ACC_z_peak': acc_z_peak,\n",
    "        #     'EMG_mean': emg_mean, 'EMG_std': emg_std, 'EMG_drange': emg_drange, 'EMG_absint': emg_absint, 'EMG_median': emg_median, 'EMG_perc_10': emg_perc_10,\n",
    "        #     'EMG_perc_90': emg_perc_90, 'EMG_peak_freq': emg_peak_freq, 'EMG_mean_freq': emg_mean_freq, 'EMG_median_freq': emg_median_freq\n",
    "        # }, ignore_index=True)\n",
    "\n",
    "        chest_df = chest_df.append({\n",
    "            'ACC_x_mean': acc_x_mean, 'ACC_y_mean': acc_y_mean, 'ACC_z_mean': acc_z_mean, 'ACC_xzy_mean': xyz_mean,\n",
    "            'ACC_x_std': acc_x_std, 'ACC_y_std': acc_y_std, 'ACC_z_std': acc_z_std, 'ACC_xyz_std': xyz_std,\n",
    "            'ACC_x_absint': acc_x_absint, 'ACC_y_absint': acc_y_absint, 'ACC_z_absint': acc_z_absint, 'ACC_xyz_absint': xyz_absint,\n",
    "            'ACC_x_peak': acc_x_peak, 'ACC_y_peak': acc_y_peak, 'ACC_z_peak': acc_z_peak,\n",
    "            'ECG_hr_mean': hr_mean, 'ECG_hr_std': hr_std, 'ECG_hrv_NN50': hrv_NN50, 'ECG_hrv_pNN50': hrv_pNN50, 'ECG_hrv_TINN': hrv_TINN, 'ECG_hrv_RMS': hrv_rms,\n",
    "            'ECG_hrv_ULF': hrv_ULF, 'ECG_hrv_LF': hrv_LF, 'ECG_hrv_HF': hrv_HF, 'ECG_hrv_VHF': hrv_VHF, 'ECG_hrv_LFHF_ratio': hrv_lf_hf_ratio, 'ECG_hrv_f_sum': hrv_f_sum,\n",
    "            'ECG_hrv_rel_ULF': hrv_rel_ULF, 'ECG_hrv_rel_LF': hrv_rel_LF, 'ECG_hrv_rel_HF': hrv_rel_HF, 'ECG_hrv_rel_VHF': hrv_rel_VHF, 'ECG_hrv_LFn': hrv_LFn, 'ECG_hrv_HFn': hrv_HFn,\n",
    "            'EDA_mean': eda_mean, 'EDA_std': eda_std, 'EDA_mean': eda_mean, 'EDA_min': eda_min, 'EDA_max': eda_max, 'EDA_slope': eda_slope,\n",
    "            'EDA_drange': eda_drange, 'EDA_SCL_mean': eda_scl_mean, 'EDA_SCL_std': eda_scl_mean, 'EDA_SCR_mean': eda_scr_mean, 'EDA_SCR_std': eda_scr_std,\n",
    "            'EDA_corr_SCL_t': eda_corr_scl_t, 'EDA_SCR_no': eda_scr_no, 'EDA_ampl_sum': eda_ampl_sum, 'EDA_scr_area': eda_scr_area,\n",
    "            'EMG_mean': emg_mean, 'EMG_std': emg_std, 'EMG_drange': emg_drange, 'EMG_absint': emg_absint, 'EMG_median': emg_median, 'EMG_perc_10': emg_perc_10,\n",
    "            'EMG_perc_90': emg_perc_90, 'EMG_peak_freq': emg_peak_freq, 'EMG_mean_freq': emg_mean_freq, 'EMG_median_freq': emg_median_freq,\n",
    "            'EMG_peak_no': emg_peak_no, 'EMG_peak_amp_mean':  emg_peak_amp_mean, 'EMG_peak_amp_std':  emg_peak_amp_std, 'EMG_peak_amp_sum':  emg_peak_amp_sum,\n",
    "            'EMG_peak_amp_norm_sum':  emg_peak_amp_norm_sum,\n",
    "            'RESP_inhal_mean': resp_inhal_mean, 'RESP_inhal_std': resp_inhal_std, 'RESP_exhal_mean': resp_exhal_mean, 'RESP_exhal_std': resp_exhal_std,\n",
    "            'RESP_ie_ratio': resp_ie_ratio, 'RESP_duration': resp_duration, 'RESP_stretch': resp_stretch, 'RESP_breath_rate': resp_breath_rate, 'RESP_volume': resp_volume,\n",
    "            'TEMP_mean': temp_mean, 'TEMP_std': temp_std, 'TEMP_min': temp_min, 'TEMP_max': temp_max, 'TEMP_drange': temp_drange, 'TEMP_slope': temp_slope\n",
    "        }, ignore_index=True)\n",
    "\n",
    "\n",
    "        # index += 1\n",
    "        # if index % 10 == 0:\n",
    "        #     break\n",
    "    \n",
    "    print('Elapsed Process', condition.shape[0], str(timedelta(seconds=time.time() - init)))\n",
    "    return chest_df, chest_df_5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7j0ECbcblDDb"
   },
   "source": [
    "## Chest-worn device - Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wf1aiK2O0oTH"
   },
   "outputs": [],
   "source": [
    "def process_subject(subject_data, cond_to_process, max_workers=6):\n",
    "    rs = dict()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_label = {executor.submit(compute_features, subject_data, cond): label for label, cond in cond_to_process}\n",
    "        for future in concurrent.futures.as_completed(future_to_label):\n",
    "            label = future_to_label[future]\n",
    "            try:\n",
    "                data, _ = future.result()\n",
    "                print(label, data.shape)\n",
    "                rs[label] = data\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (label, exc))\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "zu_aIQ-3lFsM",
    "outputId": "b30a8d40-579f-4569-9909-3a585503857a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject S7\n",
      "{'ACC': 3666600, 'ECG': 3666600, 'EMG': 3666600, 'EDA': 3666600, 'Temp': 3666600, 'Resp': 3666600}\n",
      "Baseline: (830200, 1)\n",
      "Stress: (448000, 1)\n",
      "Amusement: (260401, 1)\n",
      "Elapsed Preprocess 0:00:03.382145\n",
      "Elapsed Preprocess 0:00:04.232839\n",
      "Elapsed Preprocess 0:00:10.452032\n",
      "Elapsed Process 260401 0:02:40.979362\n",
      "amusement (1249, 77)\n",
      "Elapsed Process 448000 0:04:29.071290\n",
      "stress (2320, 77)\n",
      "Elapsed Process 830200 0:07:14.459127\n",
      "baseline (4504, 77)\n",
      "CPU times: user 38min 59s, sys: 7min 4s, total: 46min 4s\n",
      "Wall time: 7min 24s\n",
      "Generated dataset for S7 (8073, 79)\n",
      "Subject S8\n",
      "{'ACC': 3826200, 'ECG': 3826200, 'EMG': 3826200, 'EDA': 3826200, 'Temp': 3826200, 'Resp': 3826200}\n",
      "Baseline: (818300, 1)\n",
      "Stress: (469000, 1)\n",
      "Amusement: (258999, 1)\n",
      "Elapsed Preprocess 0:00:02.288148\n",
      "Elapsed Preprocess 0:00:02.823671\n",
      "Elapsed Preprocess 0:00:04.078425\n",
      "Elapsed Process 258999 0:02:34.723430\n",
      "amusement (1240, 77)\n",
      "Elapsed Process 469000 0:04:38.775093\n",
      "stress (2440, 77)\n",
      "Elapsed Process 818300 0:07:15.700035\n",
      "baseline (4436, 77)\n",
      "CPU times: user 38min 42s, sys: 7min 4s, total: 45min 46s\n",
      "Wall time: 7min 19s\n",
      "Generated dataset for S8 (8116, 79)\n",
      "Subject S9\n",
      "{'ACC': 3656100, 'ECG': 3656100, 'EMG': 3656100, 'EDA': 3656100, 'Temp': 3656100, 'Resp': 3656100}\n",
      "Baseline: (826000, 1)\n",
      "Stress: (451500, 1)\n",
      "Amusement: (260400, 1)\n",
      "Elapsed Preprocess 0:00:01.157067\n",
      "Elapsed Preprocess 0:00:01.813730\n",
      "Elapsed Preprocess 0:00:03.400825\n",
      "Elapsed Process 260400 0:02:47.912457\n",
      "amusement (1248, 77)\n",
      "Elapsed Process 451500 0:04:37.162202\n",
      "stress (2340, 77)\n",
      "Elapsed Process 826000 0:07:29.823341\n",
      "baseline (4480, 77)\n",
      "CPU times: user 39min 43s, sys: 7min 25s, total: 47min 9s\n",
      "Wall time: 7min 33s\n",
      "Generated dataset for S9 (8068, 79)\n"
     ]
    }
   ],
   "source": [
    "subjects = ['S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S13', 'S14', 'S15', 'S16', 'S17']\n",
    "for subject in subjects:\n",
    "    print('Subject', subject)\n",
    "    chest_data_dict = obj_data[subject].get_chest_data()\n",
    "    labels = obj_data[subject].get_labels()\n",
    "    chest_dict_length = {key: len(value) for key, value in chest_data_dict.items()}\n",
    "    print(chest_dict_length)\n",
    "\n",
    "    # Get labels\n",
    "    baseline = np.asarray([idx for idx,val in enumerate(labels) if val == 1])\n",
    "    stress = np.asarray([idx for idx,val in enumerate(labels) if val == 2])\n",
    "    amusement = np.asarray([idx for idx,val in enumerate(labels) if val == 3])\n",
    "\n",
    "    print(\"Baseline:\", chest_data_dict['ECG'][baseline].shape)\n",
    "    print(\"Stress:\", chest_data_dict['ECG'][stress].shape)\n",
    "    print(\"Amusement:\", chest_data_dict['ECG'][amusement].shape)\n",
    "\n",
    "    # Process Subject\n",
    "    to_process = zip(['baseline', 'stress', 'amusement'], [baseline, stress, amusement])\n",
    "    # to_process = zip(['baseline'], [baseline])\n",
    "    %time subject_data = process_subject(chest_data_dict, cond_to_process=to_process)\n",
    "\n",
    "    ## Labeling\n",
    "    subject_data['baseline']['label'] = 1\n",
    "    subject_data['baseline']['subject'] = subject\n",
    "    subject_data['stress']['label'] = 2\n",
    "    subject_data['stress']['subject'] = subject\n",
    "    subject_data['amusement']['label'] = 3\n",
    "    subject_data['amusement']['subject'] = subject\n",
    "    ## Storing\n",
    "    dfs = [v for k, v in subject_data.items()]\n",
    "    df_subject = pd.concat(dfs)\n",
    "    print('Generated dataset for', subject, df_subject.shape)\n",
    "    df_subject.head()\n",
    "    df_subject.reset_index().to_feather(f'{subject}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files If running in Google Colab\n",
    "# from google.colab import files\n",
    "# [files.download(file) for file in os.listdir('.') if file.endswith('feather')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dywVdwzo2GrG"
   },
   "source": [
    "## Chest-worn device - Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "heBO0qs_dWMR",
    "outputId": "d3e7c839-bb1d-4d73-c29e-d634f1c1be68"
   },
   "outputs": [],
   "source": [
    "subject ='S3'\n",
    "chest_data_dict = obj_data[subject].get_chest_data()\n",
    "labels = obj_data[subject].get_labels()\n",
    "chest_dict_length = {key: len(value) for key, value in chest_data_dict.items()}\n",
    "print(chest_dict_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "bwsoVGnwdt6t",
    "outputId": "13e918ce-6888-446e-a03b-8ab42b600fc5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get labels\n",
    "# labels = obj_data[subject].get_labels()\n",
    "baseline = np.asarray([idx for idx,val in enumerate(labels) if val == 1])\n",
    "stress = np.asarray([idx for idx,val in enumerate(labels) if val == 2])\n",
    "amusement = np.asarray([idx for idx,val in enumerate(labels) if val == 3])\n",
    "\n",
    "print(\"Baseline:\", chest_data_dict['ECG'][baseline].shape)\n",
    "print(\"Stress:\", chest_data_dict['ECG'][stress].shape)\n",
    "print(\"Amusement:\", chest_data_dict['ECG'][amusement].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xe20kzH-ffuE"
   },
   "outputs": [],
   "source": [
    "# For dev purposes\n",
    "# df_data, _ = compute_features(chest_data_dict, baseline)\n",
    "# df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "SQibA5GRKL6Z",
    "outputId": "97e48b72-e6a1-463e-f26c-f0342bdf4461"
   },
   "outputs": [],
   "source": [
    "# For dev purposes\n",
    "# %%time\n",
    "# to_process = zip(['baseline', 'stress', 'amusement'], [baseline, stress, amusement])\n",
    "# # to_process = zip(['baseline'], [baseline])\n",
    "\n",
    "# rs = dict()\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "#     future_to_label = {executor.submit(compute_features, chest_data_dict, cond): label for label, cond in to_process}\n",
    "#     for future in concurrent.futures.as_completed(future_to_label):\n",
    "#         label = future_to_label[future]\n",
    "#         try:\n",
    "#             data, _ = future.result()\n",
    "#             print(label, data.shape)\n",
    "#             rs[label] = data\n",
    "#         except Exception as exc:\n",
    "#             print('%r generated an exception: %s' % (label, exc))\n",
    "\n",
    "# rs['baseline']['label'] = 1\n",
    "# rs['stress']['label'] = 2\n",
    "# rs['amusement']['label'] = 3\n",
    "# dfs = [v for k, v in rs.items()]\n",
    "\n",
    "# df_s3 = pd.concat(dfs)\n",
    "# df_s3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7ZM_PY85BsD"
   },
   "source": [
    "### Loading data with Neurokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQq8A8n0dwBl"
   },
   "outputs": [],
   "source": [
    "df, bio_info = nk.bio_process(ecg=chest_data_dict[\"ECG\"][baseline].flatten(),\n",
    "                              rsp=chest_data_dict['Resp'][baseline].flatten(),\n",
    "                              emg=chest_data_dict[\"EMG\"][baseline].flatten(),\n",
    "                              eda=chest_data_dict[\"EDA\"][baseline].flatten(),\n",
    "                              sampling_rate=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "7VMyiFAtd2ir",
    "outputId": "2140e962-b6da-464b-edad-737b00288986"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PjBsmZBWEdAg",
    "outputId": "db69fbea-a973-4ade-fbd9-eb8067be64a2"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "gdjQ3ZxZerpC",
    "outputId": "4695b583-c35c-4ddf-b66e-4f29d207cfa6"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3TYvqbCW1wtz"
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "eS5eYRxlJpY0",
    "outputId": "f6a810a7-4dc1-4aff-89d8-04f63304a3b4"
   },
   "outputs": [],
   "source": [
    "# ECG\n",
    "\n",
    "# HR\n",
    "cleaned = nk.ecg_clean(chest_data_dict[\"ECG\"][baseline].flatten(), sampling_rate=700)\n",
    "rpeaks, info = nk.ecg_peaks(cleaned, sampling_rate=700, correct_artifacts=True)\n",
    "# ecg_heart_rate = nk.signal_rate(rpeaks, sampling_rate=700)\n",
    "# ecg_heart_rate\n",
    "# Features Per Window\n",
    "\n",
    "# HRV Time-domain Indices\n",
    "# HRV_MeanNN\n",
    "# HRV_SDNN\n",
    "# HRV_pNN50\n",
    "# HRV_RMSSD -> Root mean square of the HRV\n",
    "# HRV_TINN -> Triangular interpolation index\n",
    "# HRV_HTI -> Triangular interpolation index\n",
    "\n",
    "\n",
    "hrv_time = nk.hrv_time(rpeaks[0:42000], sampling_rate=700, show=False)\n",
    "hrv_time\n",
    "\n",
    "\n",
    "# hrv_time.loc[0, 'HRV_MeanNN'], hrv_time.loc[0, 'HRV_SDNN'], hrv_time.loc[0, 'HRV_pNN50'], hrv_time.loc[0, 'HRV_RMSSD'], hrv_time.loc[0, 'HRV_HTI']\n",
    "\n",
    "# TODO: get NaN values within windows\n",
    "# HRV Frequency-domain Indices\n",
    "# HRV_ULF *\n",
    "# HRV_LF *\n",
    "# HRV_HF \n",
    "# HRV_VHF\n",
    "# HRV_LFHF - Ratio LF/HF *\n",
    "# HRV_LFn *\n",
    "# HRV_HFn\n",
    "\n",
    "# hrv_freq = nk.hrv_frequency(rpeaks[0:84000], sampling_rate=700, ulf=(0.01, 0.04), lf=(0.04, 0.15), hf=(0.15, 0.4), vhf=(0.4, 1), show=True)\n",
    "# hrv_freq = nk.hrv_frequency(rpeaks[0:42000], sampling_rate=700)\n",
    "# hrv_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "ESeM9AkIlXJt",
    "outputId": "3a471245-bacb-4628-dc67-e4786b5d7b37"
   },
   "outputs": [],
   "source": [
    "!pip install biosppy pyhrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSS_PMK3P6KH"
   },
   "outputs": [],
   "source": [
    "import pyhrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "xHjsl81VLhqb",
    "outputId": "bd839f7b-7318-4d6c-d2af-934846a94e2a"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "cleaned = nk.ecg_clean(chest_data_dict[\"ECG\"][baseline].flatten()[0:42000], sampling_rate=700)\n",
    "rpeaks, info = nk.ecg_peaks(cleaned, sampling_rate=700)\n",
    "\n",
    "nn_int = pyhrv.tools.nn_intervals(info['ECG_R_Peaks'])\n",
    "\n",
    "# HR\n",
    "rs = pyhrv.time_domain.hr_parameters(nn_int)\n",
    "print(rs['hr_mean'], rs['hr_std'])\n",
    "\n",
    "#HRV\n",
    "rs_hrv = pyhrv.time_domain.nni_parameters(nn_int)\n",
    "print(rs_hrv['nni_mean'], pyhrv.time_domain.sdnn(nn_int)['sdnn'])\n",
    "print(pyhrv.time_domain.nn50(nn_int)) # nn50, pnn50\n",
    "hrv_time = nk.hrv_time(rpeaks, sampling_rate=700, show=False)\n",
    "print(hrv_time.loc[0, ['HRV_TINN']])\n",
    "print(pyhrv.time_domain.rmssd(nn_int)['rmssd'])\n",
    "\n",
    "rs = pyhrv.frequency_domain.welch_psd(nn_int, fbands={'ulf': (0.01, 0.04), 'vlf': (0.04, 0.15), 'lf': (0.15, 0.4), 'hf': (0.4, 1)}, mode='dev')\n",
    "rs = rs[0]\n",
    "rs['fft_abs'], rs['fft_ratio'], rs['fft_total'], rs['fft_rel'], rs['fft_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9UAiJGZ6lP1R",
    "outputId": "5fba913b-3264-4025-d0c3-798092a2e188"
   },
   "outputs": [],
   "source": [
    "# from biosppy.signals.ecg import ecg\n",
    "# ecg(chest_data_dict[\"ECG\"][baseline].flatten())[1:3]\n",
    "\n",
    "import  pyhrv.hrv\n",
    "\n",
    "# fbands = {'ulf': (0.0, 0.1), 'vlf': (0.1, 0.2), 'lf': (0.2, 0.3), 'hf': (0.3, 0.4)}\n",
    "%time results = pyhrv.hrv(signal=chest_data_dict[\"ECG\"][baseline].flatten()[0:42000], sampling_rate=700, plot_ecg=False, plot_tachogram=False, show=False, \\\n",
    "                          fbands={'ulf': (0.01, 0.04), 'vlf': (0.04, 0.15), 'lf': (0.15, 0.4), 'hf': (0.4, 1)}, kwargs_ecg_plot={'mode': 'dev'}, kwargs_tachogram={'show': False})\n",
    "\n",
    "# results = hrv(signal=signal)\n",
    "\n",
    "# Print all the parameters keys and values individually\n",
    "for key in results.keys():\n",
    "   print(key, results[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "keYOhEOBTesN",
    "outputId": "64e4a3f0-bf1d-4e5d-80a8-f5e7dbead229"
   },
   "outputs": [],
   "source": [
    "# Resp\n",
    "# Method biosppy important to appply bandpass filter 0.1 - 0.35 Hz\n",
    "# cleaned = nk.rsp_clean(chest_data_dict['Resp'][stress].flatten(), sampling_rate=700, method='biosppy')\n",
    "# rsp_peaks, info = nk.rsp_peaks(cleaned, sampling_rate=700)\n",
    "\n",
    "# Method biosppy important to appply bandpass filter 0.1 - 0.35 Hz\n",
    "rsp_signals, info = nk.rsp_process(chest_data_dict['Resp'][stress].flatten(), sampling_rate=700, method='biosppy')\n",
    "# fig = nk.rsp_plot(rsp_signals[0:42000]) \n",
    "\n",
    "i_duration = rsp_signals[0:42000]['RSP_Phase'][rsp_signals['RSP_Phase'] == 1].count()\n",
    "e_duration = rsp_signals[0:42000]['RSP_Phase'][rsp_signals['RSP_Phase'] == 0].count()\n",
    "print('I|E|I/E|RespDuration', i_duration, e_duration, i_duration / e_duration, (i_duration + e_duration))\n",
    "\n",
    "\n",
    "idx = np.nan\n",
    "count = 0\n",
    "duration = dict()\n",
    "first = True\n",
    "for i in rsp_signals[0:42000][~rsp_signals[0:42000]['RSP_Phase'].isnull()]['RSP_Phase'].to_numpy():\n",
    "    if i != idx:\n",
    "        if first:\n",
    "            idx = int(i)\n",
    "            duration[1] = []\n",
    "            duration [0] = []\n",
    "            first = False\n",
    "            continue\n",
    "        # print('New value', i, count)\n",
    "        duration[idx].append(count)\n",
    "        idx = int(i)\n",
    "        count = 0 \n",
    "    count += 1\n",
    "\n",
    "print(duration)\n",
    "print(\"Inhalation\", np.sum(duration[1]), np.mean(duration[1]), np.std(duration[1]), \"Exhalation\", np.sum(duration[0]), np.mean(duration[0]), np.std(duration[0]))\n",
    "print(\"Breath rate\", len(duration[1]))\n",
    "print(\"Stretch\", rsp_signals[0:42000]['RSP_Amplitude'].max() - rsp_signals[0:42000]['RSP_Amplitude'].min())\n",
    "\n",
    "\n",
    "\n",
    "resp_peaks, resp_properties = scisig.find_peaks(rsp_signals[0:42000]['RSP_Clean'], height=0)\n",
    "resp_width = scisig.peak_widths(rsp_signals[0:42000]['RSP_Clean'], resp_peaks, rel_height=0)\n",
    "resp_ht = resp_properties['peak_heights']\n",
    "volume = 0.5 * np.matmul(resp_ht, resp_width[1])  # Feature\n",
    "\n",
    "print(\"Volume\", volume)\n",
    "\n",
    "# rsp_signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "t-dMHTKIbyA1",
    "outputId": "da13d735-4f1c-4a07-b2b7-56ecf1fcce3a"
   },
   "outputs": [],
   "source": [
    "E# EDA\n",
    "filtered_5hz = nk.signal_filter(chest_data_dict['EDA'][baseline].flatten(), sampling_rate=700, highcut=5)\n",
    "# cleaned = nk.eda_clean(chest_data_dict['EDA'][baseline].flatten(), sampling_rate=700)\n",
    "cleaned = nk.standardize(filtered_5hz)\n",
    "# phasic_tonic = nk.eda_phasic(nk.standardize(cleaned), sampling_rate=700, method='cvxeda')\n",
    "# TODO: not sure about the approach. cvxeda takes longer periods\n",
    "# phasic_tonic = nk.eda_phasic(cleaned, sampling_rate=700, method='cvxeda')\n",
    "phasic_tonic = nk.eda_phasic(cleaned, sampling_rate=700)\n",
    "\n",
    "# phasic_tonic = nk.eda_phasic(cleaned, sampling_rate=700)\n",
    "# phasic_tonic\n",
    "\n",
    "# Features Per Window\n",
    "\n",
    "phasic_tonic['t'] = [(1 / 700) * i for i in range(phasic_tonic.shape[0])]\n",
    "\n",
    "# Correlation\n",
    "nk.cor(phasic_tonic['EDA_Tonic'][420000:420000 + 42000], phasic_tonic['t'][0:42000], show=False)\n",
    "\n",
    "# SCR\n",
    "scr_peaks, info = nk.eda_peaks(phasic_tonic['EDA_Phasic'], sampling_rate=700)\n",
    "scr_peaks['SCR_Peaks'][:10]\n",
    "# scr_peaks['SCR_Peaks'][0:42000].sum()\n",
    "# # Sum Amplitudes in SCR signal\n",
    "# ampl = info['SCR_Amplitude'][0:42000]\n",
    "# np.sum(ampl[~np.isnan(ampl)])\n",
    "\n",
    "# 'SCR_RiseTime' 'SCR_RecoveryTime'\n",
    "# info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YviJ9pM2vWs1",
    "outputId": "d0392385-4611-4a9a-a200-c8689b452395"
   },
   "outputs": [],
   "source": [
    "info['SCR_Peaks'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "dfK71jr3sFOx",
    "outputId": "da95bcf9-e467-4357-804e-252116c2e7da"
   },
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks, peak_widths\n",
    "\n",
    "# peaks,properties = find_peaks(cleaned, height=0)\n",
    "# # peaks,properties = find_peaks(chest_data_dict['EDA'][baseline].flatten())\n",
    "# peaks[:20]\n",
    "# # properties\n",
    "\n",
    "peaks, properties = find_peaks(cleaned[0:42000], height=0)\n",
    "width_scr = peak_widths(cleaned, peaks, rel_height=0)\n",
    "ht_scr = properties['peak_heights']\n",
    "ar_scr = 0.5*np.matmul(ht_scr,width_scr[1])\n",
    "ar_scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTJK87PaCE6d"
   },
   "outputs": [],
   "source": [
    "# nk.signal_psd??\n",
    "# scisig.periodogram?\n",
    "np.ravel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rkt5dbRheM5c",
    "outputId": "0b8014f2-8a48-47e8-f097-8536fca99ceb"
   },
   "outputs": [],
   "source": [
    "# EMG\n",
    "# More on DC Bias https://www.c-motion.com/v3dwiki/index.php/EMG:_Removing_DC_Bias\n",
    "filtered_dc = nk.signal_filter(chest_data_dict['EMG'][baseline].flatten(), sampling_rate=700, lowcut=50)\n",
    "# OR 100 Hz highpass Butterworth filter followed by a constant detrending\n",
    "# filtered_dc = nk.emg_clean(chest_data_dict['EMG'][baseline].flatten(), sampling_rate=700)\n",
    "\n",
    "\n",
    "\n",
    "# 5 sec window\n",
    "\n",
    "# Peak frequency is simply the frequency of maximum power\n",
    "f, Pxx = scisig.periodogram(filtered_dc[0:3500])\n",
    "psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "peak_freq = psd_dict[max(psd_dict.keys())]\n",
    "# Mean freq: http://luscinia.sourceforge.net/page26/page35/page35.html\n",
    "mean_freq = np.dot(Pxx, f) / np.sum(Pxx)\n",
    "avg_power = np.sum(Pxx) / 2\n",
    "# Median freq: http://luscinia.sourceforge.net/page26/page36/page36.html\n",
    "median_freq = f[(np.cumsum(f) > avg_power).argmax()]\n",
    "\n",
    "# peak_freq\n",
    "\n",
    "# TODO: verify that we're using the correct method\n",
    "# rs['Power']\n",
    "# rs = nk.signal_psd(filtered_dc[0:3500], sampling_rate=700, method='welch', min_frequency=0, max_frequency=350, show=False)\n",
    "# rs\n",
    "# rs = nk.signal_power(filtered_dc[0:3500], list(range(0, 350, 50)), sampling_rate=700, continuous=True, show=False, min_frequency=0, max_frequency=350, method='welch')\n",
    "# rs\n",
    "\n",
    "# 60 sec window\n",
    "## lowpass filter\n",
    "# filtered_50hz = nk.signal_filter(chest_data_dict['EMG'][baseline].flatten(), sampling_rate=700, highcut=50)\n",
    "# # emg, info = nk.emg_process(filtered_50hz, sampling_rate=700)\n",
    "\n",
    "# peaks, properties = find_peaks(filtered_50hz[0:42000], height = 0)\n",
    "# mn_pk_amp = np.mean(properties['peak_heights'])\n",
    "# std_pk_amp = np.std(properties['peak_heights'])\n",
    "# sum_pk_amp = np.sum(properties['peak_heights'])\n",
    "# max_pk_amp = np.abs(np.amax(properties['peak_heights']))\n",
    "# norm_sum_amp = np.sum(properties['peak_heights'] / max_pk_amp)\n",
    "\n",
    "# mn_pk_amp, std_pk_amp, sum_pk_amp, peaks.shape[0], norm_sum_amp\n",
    "# peaks.shape\n",
    "\n",
    "\n",
    "# emg_amplitude = nk.emg_amplitude(filtered_dc)\n",
    "# emg_amplitude\n",
    "\n",
    "\n",
    "\n",
    "# TODO: peaks?\n",
    "# emg['EMG_Activity'][0:42000].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_zR5vyy7gJkk"
   },
   "source": [
    "### Cardiac Activity (ECG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "e0y8J1khd5LP",
    "outputId": "1ef0bf87-e603-4e1c-95dd-b1846c283a22"
   },
   "outputs": [],
   "source": [
    "# signals, info = nk.ecg_process(df['ECG_Raw'], sampling_rate=700)\n",
    "signals, info = nk.ecg_process(chest_data_dict['ECG'][baseline].flatten(), sampling_rate=700)\n",
    "_ = nk.ecg_plot(signals)\n",
    "\n",
    "signals, info = nk.ecg_process(chest_data_dict['ECG'][stress].flatten(), sampling_rate=700)\n",
    "_ = nk.ecg_plot(signals)\n",
    "\n",
    "signals, info = nk.ecg_process(chest_data_dict['ECG'][amusement].flatten(), sampling_rate=700)\n",
    "_ = nk.ecg_plot(signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOdJAQwfgzaJ"
   },
   "source": [
    "### Respiration (Resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "k6iBIw1ad8Pk",
    "outputId": "5b427753-0920-4877-c16f-13507c771adb"
   },
   "outputs": [],
   "source": [
    "# signals, info = nk.rsp_process(df['RSP_Raw'], sampling_rate=700)\n",
    "signals, info = nk.rsp_process(chest_data_dict['Resp'][baseline].flatten(), sampling_rate=700)\n",
    "_ = nk.rsp_plot(signals)\n",
    "signals, info = nk.rsp_process(chest_data_dict['Resp'][stress].flatten(), sampling_rate=700)\n",
    "_ = nk.rsp_plot(signals)\n",
    "signals, info = nk.rsp_process(chest_data_dict['Resp'][amusement].flatten(), sampling_rate=700)\n",
    "_ = nk.rsp_plot(signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6oGR_62zhNcm"
   },
   "source": [
    "### Electromyography (EMG)\n",
    "\n",
    "*evaluating and recording the electrical activity produced by skeletal muscles*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lCIgl9Q4fKhV",
    "outputId": "5ca45ea7-65b1-42e9-e7c1-15881931f142"
   },
   "outputs": [],
   "source": [
    "signals, info = nk.emg_process(chest_data_dict['EMG'][baseline].flatten(), sampling_rate=700)\n",
    "_ = nk.emg_plot(signals)\n",
    "signals, info = nk.emg_process(chest_data_dict['EMG'][stress].flatten(), sampling_rate=700)\n",
    "_ = nk.emg_plot(signals)\n",
    "signals, info = nk.emg_process(chest_data_dict['EMG'][amusement].flatten(), sampling_rate=700)\n",
    "_ = nk.emg_plot(signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jr5fIfCunhaO"
   },
   "source": [
    "### Electrodermal Activity (EDA)\n",
    "\n",
    "*Measure of neurally mediated effects on sweat gland permeability, observed as changes in the resistance of the skin to a small electrical current, or as differences in the electrical potential between different parts of the skin.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "colab_type": "code",
    "id": "y5kNyEB4kRPm",
    "outputId": "8f97aa43-47ca-4cd0-a7c3-abb905bd67f8"
   },
   "outputs": [],
   "source": [
    "signals, info = nk.eda_process(chest_data_dict['EDA'][baseline].flatten(), sampling_rate=700)\n",
    "_ = nk.eda_plot(signals)\n",
    "signals, info = nk.eda_process(chest_data_dict['EDA'][stress].flatten(), sampling_rate=700)\n",
    "_ = nk.eda_plot(signals)\n",
    "signals, info = nk.eda_process(chest_data_dict['EDA'][amusement].flatten(), sampling_rate=700)\n",
    "_ = nk.eda_plot(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kB0GtlTvkoVt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_MArXmFg3Cpg"
   },
   "source": [
    "## Wrist-band device - Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3IeFLwcH3AUQ",
    "outputId": "7c382b7e-4f34-4c19-ab9b-441448cc71ba"
   },
   "outputs": [],
   "source": [
    "wrist_data_dict = obj_data[subject].get_wrist_data()\n",
    "wrist_dict_length = {key: len(value) for key, value in wrist_data_dict.items()}\n",
    "print(wrist_dict_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKdtGCQH3Z2l"
   },
   "source": [
    "### Commented code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KK6bJjO28uH9"
   },
   "outputs": [],
   "source": [
    "# def get_labels_by_sampling_rate(labels, condition_types, sampling_rate):\n",
    "#     rate = int(np.ceil(700 / sampling_rate))\n",
    "\n",
    "#     j = 0\n",
    "#     new_labels = []\n",
    "#     each700 = 0\n",
    "#     count = 0\n",
    "#     for j in range(len(labels)):\n",
    "#         each700 += 1\n",
    "#         if ((j % rate) == 0):\n",
    "#             new_labels.append(labels[j])\n",
    "#             count += 1\n",
    "#         if ((each700) == 700):\n",
    "#             if (count < sampling_rate):\n",
    "#                 if ((j % rate) == 0):\n",
    "#                     new_labels.append(labels[j+1])\n",
    "#                 else:\n",
    "#                     new_labels.append(labels[j])\n",
    "#             count = 0\n",
    "#             each700 = 0\n",
    "\n",
    "#     # indexes = np.ndarray((0,))\n",
    "#     # for cond in condition_types:\n",
    "#     #     indexes = np.concatenate((indexes, np.asarray([idx for idx,val in enumerate(labels) if val == cond])), axis=0)\n",
    "#     # return indexes\n",
    "#     baseline = np.asarray([idx for idx,val in enumerate(new_labels) if val == 1])\n",
    "#     stress = np.asarray([idx for idx,val in enumerate(new_labels) if val == 2])\n",
    "#     amusement = np.asarray([idx for idx,val in enumerate(new_labels) if val == 3])\n",
    "#     return (baseline, stress, amusement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqLvdQf0ANPD"
   },
   "outputs": [],
   "source": [
    "# baseline_64, stress_64, amusement_64 = get_labels_by_sampling_rate(labels, [1, 2, 3], 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uPnUxW3a43nU"
   },
   "outputs": [],
   "source": [
    "# baseline_64.shape, stress_64.shape, amusement_64.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l4RrRIxpg69f"
   },
   "outputs": [],
   "source": [
    "# labels_64 = np.hstack((baseline_64, stress_64, amusement_64))\n",
    "# assert(labels_64.shape[0] == (baseline_64.shape[0] + stress_64.shape[0] + amusement_64.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jPZJqsviDfX"
   },
   "outputs": [],
   "source": [
    "# baseline_32, stress_32, amusement_32 = get_labels_by_sampling_rate(labels, [1, 2, 3], 32)\n",
    "# labels_32 = np.hstack((baseline_32, stress_32, amusement_32))\n",
    "# baseline_4, stress_4, amusement_4 = get_labels_by_sampling_rate(labels, [1, 2, 3], 4)\n",
    "# labels_4 = np.hstack((baseline_4, stress_4, amusement_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GkB5y1r3Lvo"
   },
   "outputs": [],
   "source": [
    "# Get labels\n",
    "# baseline_64 = np.asarray([idx for idx,val in enumerate(wrist_labels_64) if val == 1])\n",
    "# stress_64 = np.asarray([idx for idx,val in enumerate(wrist_labels_64) if val == 2])\n",
    "# amusement_64 = np.asarray([idx for idx,val in enumerate(wrist_labels_64) if val == 3])\n",
    "\n",
    "# print(\"Baseline:\", wrist_data_dict['BVP'][baseline_64].shape)\n",
    "# print(\"Stress:\", wrist_data_dict['BVP'][stress_64].shape)\n",
    "# print(\"Amusement:\", wrist_data_dict['BVP'][amusement_64].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fA5K2i9K7eTh"
   },
   "source": [
    "### Loading Data utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qId_3l4694IE"
   },
   "outputs": [],
   "source": [
    "class EDAUtils():\n",
    "\n",
    "    mod_samp_rate = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4, 'Resp': 700, 'label': 700}\n",
    "\n",
    "    WINDOW_SIZE = 60 # in seconds\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_signal_fir(data, sampling_rate, cutoff=0.4, numtaps=64):\n",
    "        \"\"\"\n",
    "            Applies a low-pass filter to accelerometer data\n",
    "            # https://github.com/MITMediaLabAffectiveComputing/eda-explorer/blob/master/AccelerometerFeatureExtractionScript.py\n",
    "\n",
    "        \"\"\"\n",
    "        # f = cutoff / (sampling_rate / 2.0)\n",
    "        nyq = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        FIR_coeff = scisig.firwin(numtaps, normal_cutoff)\n",
    "\n",
    "        return scisig.lfilter(FIR_coeff, 1, data)\n",
    "\n",
    "    @staticmethod\n",
    "    def butter_lowpass_filter(data, sampling_rate, cutoff, order=5):\n",
    "        \"\"\"\n",
    "            Gets filtered data using a low-pass butterworth filter (cutoff: (Hz), fs: (Hz), order: (?))\n",
    "            Finally, applies a low-pass butterworth filter to EDA data\n",
    "            # https://github.com/MITMediaLabAffectiveComputing/eda-explorer/blob/master/load_files.py\n",
    "        \"\"\"\n",
    "\n",
    "        nyq = 0.5 * sampling_rate # Nyquist Frequecy (half-cycles / sample) for digital filters\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        b, a = scisig.butter(order, normal_cutoff, btype='lowpass', analog=False)\n",
    "\n",
    "        # Filtering Helper functions\n",
    "        y = scisig.lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def eda_stats(data, sampling_rate):\n",
    "        \"\"\"\n",
    "            Uses the CVXEDA Convex optimization approach to EDA signal processing\n",
    "            # https://github.com/lciti/cvxEDA/blob/master/src/cvxEDA.py\n",
    "        \"\"\"\n",
    "        zscore = (data - data.mean()) / data.std()\n",
    "        [r, p, t, l, d, e, obj] = cvxEDA.cvxEDA(zscore, 1. / sampling_rate)\n",
    "        return [r, p, t, l, d, e, obj]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_net_acc(data):\n",
    "        \"\"\"\n",
    "            Get Euclidean norm of ACC modality across the three axes\n",
    "        \"\"\"\n",
    "        return data.apply(lambda data: np.sqrt(data['ACC_x'] ** 2 + data['ACC_y'] ** 2 + data['ACC_z'] ** 2), axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_stats(data, label=-1):\n",
    "        mean_features = np.mean(data)\n",
    "        std_features = np.std(data)\n",
    "        min_features = np.amin(data)\n",
    "        max_features = np.amax(data)\n",
    "\n",
    "        features = {'mean': mean_features, 'std': std_features, 'min': min_features, 'max': max_features,\n",
    "                    'label': label}\n",
    "        return features\n",
    "\n",
    "    @staticmethod\n",
    "    def get_peak_freq(x):\n",
    "        \"\"\"\n",
    "            TODO:\n",
    "        \"\"\"\n",
    "        f, Pxx = scisig.periodogram(x, fs=8)\n",
    "        psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "        peak_freq = psd_dict[max(psd_dict.keys())]\n",
    "        return peak_freq\n",
    "\n",
    "    @staticmethod\n",
    "    def get_slope(series):\n",
    "        linreg = scipy.stats.linregress(np.arange(len(series)), series )\n",
    "        slope = linreg[0]\n",
    "        return slope\n",
    "\n",
    "    def downsample(data, sampling_rate, label):\n",
    "        \"\"\"\n",
    "            As labels were set using a sampling freq of 700 Hz, it is considered as reference frequency due to\n",
    "            encompass the lesser ones in its resolution.\n",
    "        \"\"\"\n",
    "        # no_windows = int(data.shape[0] / (sampling_rate * EDAUtils.WINDOW_SIZE))\n",
    "        samples = []\n",
    "        \n",
    "        window_size = int(sampling_rate * EDAUtils.WINDOW_SIZE)\n",
    "        window_shift = 0.25\n",
    "\n",
    "        for i in range(0, data.shape[0] - window_size, sampling_rate * window_shift):\n",
    "            # Get window of data\n",
    "            # w = data[window_size * i: window_size * (i + 1)].copy()\n",
    "            w = data[i: window_size + i].copy()\n",
    "\n",
    "            # Add/Calc acc norm\n",
    "            w['ACC_net'] = EDAUtils.get_net_acc(w) # Feature\n",
    "            \n",
    "            # Calculate stats for window\n",
    "            wstats = EDAUtils.get_stats(w, label=label) # Feature\n",
    "\n",
    "            # Seperating sample and label\n",
    "            x = pd.DataFrame(wstats).drop('label', axis=0)\n",
    "            y = x['label'][0]\n",
    "            x.drop('label', axis=1, inplace=True)\n",
    "\n",
    "            feat_names = []\n",
    "            for row in x.index:\n",
    "                for col in x.columns:\n",
    "                    feat_names.append('_'.join([row, col]))\n",
    "\n",
    "            wdf = pd.DataFrame(x.values.flatten()).T\n",
    "            wdf.columns = feat_names\n",
    "            wdf = pd.concat([wdf, pd.DataFrame({'label': y}, index=[0])], axis=1)\n",
    "            \n",
    "            # More feats\n",
    "            wdf['BVP_peak_freq'] = EDAUtils.get_peak_freq(w['BVP'].dropna()) # Feature\n",
    "            # TODO: Empty cases \n",
    "            # print('TEMP', w['TEMP'].dropna())\n",
    "            wdf['TEMP_slope'] = EDAUtils.get_slope(w['TEMP'].dropna()) # Feature\n",
    "            samples.append(wdf)\n",
    "\n",
    "        return pd.concat(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nipjWrDZxXR4"
   },
   "source": [
    "### Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRnbjkudqKMA"
   },
   "outputs": [],
   "source": [
    "eda_df = pd.DataFrame(wrist_data_dict['EDA'], columns=['EDA'])\n",
    "bvp_df = pd.DataFrame(wrist_data_dict['BVP'], columns=['BVP'])\n",
    "acc_df = pd.DataFrame(wrist_data_dict['ACC'], columns=['ACC_x', 'ACC_y', 'ACC_z'])\n",
    "temp_df = pd.DataFrame(wrist_data_dict['TEMP'], columns=['TEMP'])\n",
    "resp_df = pd.DataFrame(wrist_data_dict['Resp'], columns=['Resp'])\n",
    "\n",
    "label_df = pd.DataFrame(labels, columns=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53HoYj1T9ZJD"
   },
   "source": [
    "#### Signal pre-processing: Applying filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yaP9_ysTrRkV"
   },
   "outputs": [],
   "source": [
    "# Signal preprocessing - Applying filters\n",
    "eda_df['EDA'] = EDAUtils.butter_lowpass_filter(eda_df['EDA'], EDAUtils.mod_samp_rate['EDA'], 1., 6)\n",
    "\n",
    "for _ in acc_df.columns:\n",
    "    acc_df[_] = EDAUtils.filter_signal_fir(acc_df.values, EDAUtils.mod_samp_rate['ACC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F8n5HxVdxxsF"
   },
   "source": [
    "#### Index to datetime based on sampling freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6OPz9qIO90rI"
   },
   "outputs": [],
   "source": [
    "eda_df.index = pd.to_datetime([(1 / EDAUtils.mod_samp_rate['EDA']) * i for i in range(eda_df.shape[0])], unit='s')\n",
    "bvp_df.index = pd.to_datetime([(1 / EDAUtils.mod_samp_rate['BVP']) * i for i in range(bvp_df.shape[0])], unit='s')\n",
    "acc_df.index = pd.to_datetime([(1 / EDAUtils.mod_samp_rate['ACC']) * i for i in range(acc_df.shape[0])], unit='s')\n",
    "temp_df.index = pd.to_datetime([(1 / EDAUtils.mod_samp_rate['TEMP']) * i for i in range(temp_df.shape[0])], unit='s')\n",
    "resp_df.index = pd.to_datetime([(1 / EDAUtils.mod_samp_rate['Resp']) * i for i in range(resp_df.shape[0])], unit='s')\n",
    "\n",
    "label_df.index = pd.to_datetime([(1 / EDAUtils.mod_samp_rate['label']) * i for i in range(label_df.shape[0])], unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdtTrbbF-ga3"
   },
   "source": [
    "#### Getting extra features from EDA Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "1XZwda1H-g2m",
    "outputId": "c65e555c-69d9-4b46-a025-9c143954a9e5"
   },
   "outputs": [],
   "source": [
    "## SMNA -> Sudomotor Nerve Activity -> https://www.centropiaggio.unipi.it/sites/default/files/greco2015cvxeda.pdf\n",
    "scr_phasic, smna, scl_tonic, _, _, _, _ = EDAUtils.eda_stats(eda_df['EDA'], EDAUtils.mod_samp_rate['EDA'])\n",
    "eda_df['EDA_scr'] = scr_phasic # Feature\n",
    "eda_df['EDA_smna'] = smna\n",
    "eda_df['EDA_scl'] = scl_tonic # Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-L4g_M68ESfy"
   },
   "source": [
    "#### Joining modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqQdNfbO-AFQ"
   },
   "outputs": [],
   "source": [
    "df_wrist = eda_df.join(bvp_df, how='outer')\n",
    "df_wrist = df_wrist.join(temp_df, how='outer')\n",
    "df_wrist = df_wrist.join(acc_df, how='outer')\n",
    "df_wrist = df_wrist.join(resp_df, how='outer')\n",
    "df_wrist = df_wrist.join(label_df, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "alLKvrVSyL3P",
    "outputId": "01abe29a-d734-4f25-c43f-07cb38bffaa0"
   },
   "outputs": [],
   "source": [
    "eda_df.shape, bvp_df.shape, acc_df.shape, temp_df.shape, resp_df.shape, label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hx72iJ3NC4Qu",
    "outputId": "40468fcf-c1c3-462c-b2cd-00da0f008ba1"
   },
   "outputs": [],
   "source": [
    "df_wrist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N_79XP8R-CMv",
    "outputId": "80141ca2-dc74-4e53-8993-3a230e4d9e00"
   },
   "outputs": [],
   "source": [
    "df_wrist['label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wZN_jy_5-TyC",
    "outputId": "32b07fe1-b2f8-4ad5-a596-1eae8266b7ed"
   },
   "outputs": [],
   "source": [
    "df_wrist.shape[0] - df_wrist['label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Ck8LqrXv5hN7",
    "outputId": "09ec9d8e-38cd-4b8e-ea6f-6b91e23a509b"
   },
   "outputs": [],
   "source": [
    "df_wrist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88gowoLOyf3I"
   },
   "source": [
    "#### Filling NA Values on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JGYkNrFZGG_D"
   },
   "outputs": [],
   "source": [
    "df_wrist['label'] = df_wrist['label'].fillna(method='bfill')\n",
    "df_wrist.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "xC4N7j7lGpg-",
    "outputId": "43d01d66-9807-43e7-ed0e-17e653d96ab1"
   },
   "outputs": [],
   "source": [
    "df_wrist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DSVw3PKI5vbE",
    "outputId": "8c4258ff-104b-4396-e0ef-04bed2df0700"
   },
   "outputs": [],
   "source": [
    "df_wrist['label'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmbvjcUfy6kD"
   },
   "source": [
    "#### Split Dataset based on Affective Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1l8ZYpvPHJSe",
    "outputId": "bfb101dc-68d7-4ecb-c746-7db151b31304"
   },
   "outputs": [],
   "source": [
    "df_wrist_grouped = df_wrist.groupby('label')\n",
    "baseline_wrist = df_wrist_grouped.get_group(1)\n",
    "stress_wrist = df_wrist_grouped.get_group(2)\n",
    "amusement_wrist = df_wrist_grouped.get_group(3)\n",
    "baseline_wrist.shape, stress_wrist.shape, amusement_wrist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfXx08L9zVLH"
   },
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hu7A2P9bzbbI"
   },
   "outputs": [],
   "source": [
    "baseline_wrist_sample = EDAUtils.downsample(baseline_wrist, EDAUtils.mod_samp_rate['label'], 1)\n",
    "stress_wrist_sample = EDAUtils.downsample(stress_wrist, EDAUtils.mod_samp_rate['label'], 2)\n",
    "amusement_wrist_sample = EDAUtils.downsample(amusement_wrist, EDAUtils.mod_samp_rate['label'], 3) # 0 ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erX7wKRakXEK"
   },
   "outputs": [],
   "source": [
    "wrist_all_samples = pd.concat([baseline_wrist_sample, stress_wrist_sample, amusement_wrist_sample])\n",
    "wrist_all_samples = pd.concat([wrist_all_samples.drop('label', axis=1), pd.get_dummies(wrist_all_samples['label'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mVf06Pwr1rQJ"
   },
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "OTiOdGADoMAH",
    "outputId": "31a0a12b-19a9-4053-e956-77524155733c"
   },
   "outputs": [],
   "source": [
    "wrist_all_samples['label'] = (wrist_all_samples[3].astype(str) + wrist_all_samples[1].astype(str) + wrist_all_samples[2].astype(str)).apply(lambda x: x.index('1'))\n",
    "wrist_all_samples.drop([3, 1, 2], axis=1, inplace=True)\n",
    "wrist_all_samples.reset_index(drop=True, inplace=True)\n",
    "wrist_all_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9fZvTa2Wolng",
    "outputId": "976776a2-ca69-4629-a463-a230fe6fb9ca"
   },
   "outputs": [],
   "source": [
    "wrist_all_samples.shape[0], wrist_all_samples[wrist_all_samples['label'] == 1].shape[0], wrist_all_samples[wrist_all_samples['label'] == 2].shape[0], wrist_all_samples[wrist_all_samples['label'] == 3].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Gn7gI8u8tr_R",
    "outputId": "6844432a-56e5-4582-d9df-206b465ba6a9"
   },
   "outputs": [],
   "source": [
    "wrist_all_samples.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QqkeZuf_WNv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPNwvrDZMkTVXfJiCdmJhiL",
   "collapsed_sections": [
    "PSRQ7dUs33ru",
    "3TYvqbCW1wtz",
    "_zR5vyy7gJkk",
    "sOdJAQwfgzaJ",
    "6oGR_62zhNcm",
    "jr5fIfCunhaO",
    "qKdtGCQH3Z2l"
   ],
   "include_colab_link": true,
   "name": "WESAD - Data Exploration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
