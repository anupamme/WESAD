{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/Users/santteegt/anaconda3/envs/pysyft-dev/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.2.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/santteegt/anaconda3/envs/pysyft-dev/lib/python3.7/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import syft as sy\n",
    "from syft.execution.plan import Plan\n",
    "\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# force protobuf serialization for tensors\n",
    "hook.local_worker.framework = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Python implementation of LSTMCell for MPC\n",
    "    This class overrides the torch.nn.LSTMCell\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True, nonlinearity=None):\n",
    "        super(LSTMCell, self).__init__()\n",
    "    \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.nonlinearity = nonlinearity\n",
    "\n",
    "\n",
    "        # Input Gate\n",
    "        self.fc_xi = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.fc_hi = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "        \n",
    "        # Forget Gate\n",
    "        self.fc_xf = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.fc_hf = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "\n",
    "        # Cell Gate\n",
    "        self.fc_xc = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.fc_hc = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "\n",
    "        # Output Gate\n",
    "        self.fc_xo = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.fc_ho = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "        \n",
    "        self.init_parameters()\n",
    "        \n",
    "    def init_parameters(self):\n",
    "        std = 1.0 / np.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "        \n",
    "#     def init_hidden(self, input):\n",
    "#         \"\"\"\n",
    "#         TODO: Not being used \n",
    "#         This method initializes a hidden state when no hidden state is provided\n",
    "#         in the forward method. It creates a hidden state with zero values.\n",
    "#         \"\"\"\n",
    "# #         h = torch.zeros(input.shape[0], self.hidden_size, dtype=input.dtype, device=input.device)\n",
    "#         h = torch.zeros(input.shape[0], self.hidden_size)\n",
    "#         if input.has_child() and isinstance(input.child, PointerTensor):\n",
    "#             h = h.send(input.child.location)\n",
    "#         if input.has_child() and isinstance(input.child, precision.FixedPrecisionTensor):\n",
    "#             h = h.fix_precision()\n",
    "#             child = input.child\n",
    "#             if isinstance(child.child, AdditiveSharingTensor):\n",
    "#                 crypto_provider = child.child.crypto_provider\n",
    "#                 owners = child.child.locations\n",
    "#                 h = h.share(*owners, crypto_provider=crypto_provider)\n",
    "#         return h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, x, hc=None):\n",
    "\n",
    "        if hc is None:\n",
    "            batch_size = x.shape[1]\n",
    "            hc = (self.init_hidden(batch_size), self.init_hidden(batch_size))\n",
    "        h, c = hc\n",
    "        \n",
    "#         print('LSTMCell', type(x), x.shape)\n",
    "#         print('Hidden', h, h.shape)\n",
    "#         print('C t-1', c, c.shape) \n",
    "        x_i = self.fc_xi(x)\n",
    "        h_i = self.fc_hi(h)\n",
    "        x_f = self.fc_xf(x)\n",
    "        h_f = self.fc_hf(h)\n",
    "        x_c = self.fc_xc(x)\n",
    "        h_c = self.fc_hc(h)\n",
    "        x_o = self.fc_xo(x)\n",
    "        h_o = self.fc_ho(h)\n",
    "        \n",
    "        inputgate = (x_i + h_i).sigmoid()\n",
    "        forgetgate = (x_f + h_f).sigmoid()\n",
    "        cellgate = (x_c + h_c).tanh()\n",
    "        outputgate = (x_o + h_o).sigmoid()\n",
    "\n",
    "#         c_ = torch.mul(forgetgate, c) + torch.mul(inputgate, cellgate)\n",
    "        c_ = (forgetgate * c) + (inputgate * cellgate)\n",
    "\n",
    "#         h_ = torch.mul(outputgate, torch.tanh(c_))\n",
    "        h_ = outputgate * c_.tanh()\n",
    "#         print('h', h_)\n",
    "\n",
    "        return h_, c_\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    V2\n",
    "    Python implementation of LSTM for MPC\n",
    "    This class overrides the torch.nn.LSTM\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers=1,\n",
    "        bias=True,\n",
    "        batch_first=False,\n",
    "        dropout=0,\n",
    "        bidirectional=False,\n",
    "        nonlinearity=None,\n",
    "    ):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "        self.batch_first = batch_first\n",
    "#         self.dropout = float(dropout)\n",
    "        self.bidirectional = bidirectional\n",
    "#         self.num_directions = 2 if bidirectional else 1\n",
    "#         self.is_lstm = base_cell is LSTMCell\n",
    "        self.nonlinearity = nonlinearity\n",
    "    \n",
    "        # Dropout layers\n",
    "        # TODO: implement a nn.Dropout class for PySyft\n",
    "        # Link to issue: https://github.com/OpenMined/PySyft/issues/2500\n",
    "\n",
    "        # Build RNN forward layers\n",
    "        sizes = [input_size, *(hidden_size for _ in range(self.num_layers - 1))]\n",
    "        print('sizes', sizes)\n",
    "        self.rnn_forward = nn.ModuleList(\n",
    "            (LSTMCell(sz, hidden_size, bias, nonlinearity) for sz in sizes)\n",
    "        )\n",
    "        \n",
    "        self.lstm_cell = LSTMCell(self.input_size, self.hidden_size, self.bias, self.nonlinearity)\n",
    "\n",
    "#         # Build RNN backward layers, if needed\n",
    "#         if self.bidirectional:\n",
    "#             self.rnn_backward = nn.ModuleList(\n",
    "#                 (base_cell(sz, hidden_size, bias, nonlinearity) for sz in sizes)\n",
    "#             )\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "    def forward(self, x, hc=None):\n",
    "        \n",
    "        batch_size = x.shape[1]\n",
    "        seq_len = x.shape[0]\n",
    "        \n",
    "        if hc is None:\n",
    "            print('Init hc...')\n",
    "            hc = (self.init_hidden(batch_size), self.init_hidden(batch_size))\n",
    "            \n",
    "        # Run through rnn in the forward direction\n",
    "        for t in range(seq_len):\n",
    "            input_ = x.select(0, t).view(1, -1)\n",
    "            hc = self.lstm_cell(input_, hc)\n",
    "                \n",
    "        return hc\n",
    "\n",
    "    \n",
    "class WesadLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=3, lstm_layers=1, dropout=0.2):\n",
    "        # super(WesadLSTM, self).__init__(id=\"encrypted-model\")\n",
    "        super(WesadLSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.classes = output_dim\n",
    "        self.lstm = LSTM(input_size=input_dim, hidden_size=input_dim, num_layers=lstm_layers, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return self.lstm.init_hidden(batch_size), self.lstm.init_hidden(batch_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        lstm_out, _ = self.lstm(x, h)\n",
    "        out = self.fc(lstm_out.view(-1, self.hidden_dim))\n",
    "#         out = F.softmax(out.view(-1, self.classes), dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_params(module, params_list, start_param_idx=0):\n",
    "    \"\"\"\n",
    "    Set params list into model recursively.\n",
    "    \"\"\"\n",
    "    param_idx = start_param_idx\n",
    "\n",
    "    for name, param in module._parameters.items():\n",
    "        print('param name', name)\n",
    "        # A param can be None if it is not trainable.\n",
    "        if param is not None:\n",
    "            module._parameters[name] = params_list[param_idx]\n",
    "            param_idx += 1\n",
    "\n",
    "    for name, child in module._modules.items():\n",
    "        print('module name', name)\n",
    "        if child is not None:\n",
    "            param_idx = set_model_params(child, params_list, param_idx)\n",
    "\n",
    "    return param_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_with_logits(logits, targets, batch_size):\n",
    "    \"\"\" Calculates softmax entropy\n",
    "        Args:\n",
    "            * logits: (NxC) outputs of dense layer\n",
    "            * targets: (NxC) one-hot encoded labels\n",
    "            * batch_size: value of N, temporarily required because Plan cannot trace .shape\n",
    "    \"\"\"\n",
    "    # numstable logsoftmax\n",
    "    norm_logits = logits - logits.max()\n",
    "    log_probs = norm_logits - norm_logits.exp().sum(dim=1, keepdim=True).log()\n",
    "    # NLL, reduction = mean\n",
    "    return -(targets * log_probs).sum() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sgd(param, **kwargs):\n",
    "    print('param', param, param.shape)\n",
    "    print(kwargs['lr'])\n",
    "    print(param.requires_grad, param.grad)\n",
    "#     return param - (kwargs['lr'] * param.grad if param.grad is not None else torch.zeros_like(param))\n",
    "    return param - (kwargs['lr'] * param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 25\n",
    "val_batch_size = 5\n",
    "input_dim = 77\n",
    "output_dim = 3\n",
    "lstm_layers = 1\n",
    "dropout = 0.5\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes [77]\n"
     ]
    }
   ],
   "source": [
    "model = WesadLSTM(input_dim=input_dim, hidden_dim=input_dim, output_dim=output_dim, lstm_layers=lstm_layers,\n",
    "                  dropout=dropout)\n",
    "\n",
    "@sy.func2plan()\n",
    "def train(data, target, h, c, batch_size, lr, model_parameters):\n",
    "    set_model_params(model, model_parameters)\n",
    "    out = model(data, (h, c))\n",
    "    \n",
    "#     batch_size = out.shape[0]\n",
    "    # loss = ((out - target)**2).sum().refresh()/batch_size\n",
    "#     loss = ((out - target)**2).sum()/batch_size\n",
    "    loss = softmax_cross_entropy_with_logits(out, target, batch_size)\n",
    "    print('loss', loss)\n",
    "    loss.backward()\n",
    "    \n",
    "    print('post backprop')\n",
    "    \n",
    "    # step\n",
    "    updated_params = [\n",
    "        naive_sgd(param, lr=lr)\n",
    "        for param in model_parameters\n",
    "    ]\n",
    "\n",
    "    return (loss, *updated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = model_state[0]\n",
    "# p.uniform_??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([77, 77]), False),\n",
       " (torch.Size([77]), False),\n",
       " (torch.Size([3, 77]), False),\n",
       " (torch.Size([3]), False)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # model_state = list(model.parameters())\n",
    "model_state = [param.data for param in model.parameters()] # raw tensors instead of nn.Parameter\n",
    "[(m.shape, m.requires_grad) for m in model_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data torch.Size([25, 77])\n",
      "target torch.Size([25, 3])\n",
      "hc torch.Size([25, 77]) torch.Size([25, 77])\n"
     ]
    }
   ],
   "source": [
    "# model_state = list(model.parameters())\n",
    "# model_state = [param.data for param in model.parameters()] # raw tensors instead of nn.Parameter\n",
    "\n",
    "data = torch.randn((train_batch_size, input_dim), dtype=torch.float32)\n",
    "print('data', data.shape)\n",
    "\n",
    "target = torch.randint(0, output_dim - 1, (train_batch_size,))\n",
    "target = nn.functional.one_hot(target, output_dim)\n",
    "print('target', target.shape)\n",
    "\n",
    "h, c = model.init_hidden(train_batch_size)\n",
    "print('hc', h.shape, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model_state = list(model.parameters())\n",
    "# model_state = [param.data for param in model.parameters()] # raw tensors instead of nn.Parameter\n",
    "\n",
    "# data = torch.randn((train_batch_size, input_dim), dtype=torch.float32)\n",
    "\n",
    "# target = torch.randint(0, output_dim - 1, (train_batch_size,))\n",
    "# target = nn.functional.one_hot(target, output_dim)\n",
    "# target.shape\n",
    "\n",
    "# h, c = model.init_hidden(train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module name lstm\n",
      "module name rnn_forward\n",
      "module name 0\n",
      "module name fc_xi\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_hi\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_xf\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_hf\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_xc\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_hc\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_xo\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_ho\n",
      "param name weight\n",
      "param name bias\n",
      "module name lstm_cell\n",
      "module name fc_xi\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_hi\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_xf\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_hf\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_xc\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_hc\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_xo\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc_ho\n",
      "param name weight\n",
      "param name bias\n",
      "module name fc\n",
      "param name weight\n",
      "param name bias\n",
      "loss AutogradTensor>PlaceHolder[Id:67798322502]>tensor([1.1027])\n",
      "post backprop\n",
      "param AutogradTensor>PlaceHolder[Id:25902286165]>tensor([[ 0.0139,  0.0295, -0.1039,  ...,  0.0599,  0.0137,  0.1030],\n",
      "        [-0.0509, -0.0202,  0.0262,  ..., -0.0787, -0.0414,  0.0207],\n",
      "        [-0.0903, -0.0056, -0.0546,  ..., -0.0409, -0.0791, -0.0767],\n",
      "        ...,\n",
      "        [ 0.0489, -0.0235, -0.0423,  ...,  0.0455, -0.0223, -0.0515],\n",
      "        [ 0.0666,  0.0401,  0.1029,  ...,  0.0183,  0.0396,  0.0192],\n",
      "        [ 0.0930,  0.1048, -0.0627,  ..., -0.0807,  0.0460, -0.0372]]) torch.Size([77, 77])\n",
      "AutogradTensor>PlaceHolder[Id:81241644852]>tensor([1.0000e-04])\n",
      "True None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mul(): argument 'other' (position 1) must be Tensor, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-053ac094062c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmodel_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             trace_autograd=True)\n\u001b[0m",
      "\u001b[0;32m~/openmined/PySyft/syft/execution/plan.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, trace_autograd, *args)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m# print('Args', args)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# print('Framework args', framework_kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mframework_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# Register inputs in role\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-35b9f3ec8aa9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, target, h, c, batch_size, lr, model_parameters)\u001b[0m\n\u001b[1;32m     19\u001b[0m     updated_params = [\n\u001b[1;32m     20\u001b[0m         \u001b[0mnaive_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     ]\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-35b9f3ec8aa9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m     updated_params = [\n\u001b[1;32m     20\u001b[0m         \u001b[0mnaive_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     ]\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cbaf2cbf1668>\u001b[0m in \u001b[0;36mnaive_sgd\u001b[0;34m(param, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     return param - (kwargs['lr'] * param.grad if param.grad is not None else torch.zeros_like(param))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/openmined/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutogradTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutogradTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__neg__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openmined/PySyft/syft/frameworks/torch/tensors/interpreters/autograd.py\u001b[0m in \u001b[0;36mmethod_with_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 )\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;31m# Put back SyftTensor on the tensors found in the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openmined/PySyft/syft/generic/frameworks/hook/tensors.py\u001b[0m in \u001b[0;36mtracing_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcreate_tracing_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mtracing_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m                 \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openmined/PySyft/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_syft_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;31m# Send it to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openmined/PySyft/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# means that there is a wrapper to remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/openmined/PySyft/syft/generic/frameworks/hook/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mul(): argument 'other' (position 1) must be Tensor, not NoneType"
     ]
    }
   ],
   "source": [
    "# Plan._build_translators = []\n",
    "\n",
    "train.build(data, \n",
    "            target, \n",
    "            h, c,\n",
    "            torch.tensor([train_batch_size]),\n",
    "            torch.tensor([lr]),\n",
    "            model_state, \n",
    "            trace_autograd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
